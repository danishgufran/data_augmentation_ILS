{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "Urn8piKzSqxQ",
        "outputId": "5fb37862-862a-44d5-db28-c84d80d56de0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Author - Danish Gufran\\n           - Jadon Johnson\\n           - Isaac Blair\\n           - Sudeep Pasricha\\n\\nEPIC Lab : Colorado State University, Fort Collins\\n\\n<Danish.Gufran@colostate.edu>\\n<Jadon.Johnson@colostate.edu>\\n<Isaac.Blair@colostate.edu>\\n<Sudeep@colostate.edu>\\n\\nTitle - Data Augmentation Methods for Wi-Fi RSS Fingerprinting Based Indoor Localization.\\n\\nCitation :\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "''' Author - Danish Gufran\n",
        "           - Jadon Johnson\n",
        "           - Isaac Blair\n",
        "           - Sudeep Pasricha\n",
        "\n",
        "EPIC Lab : Colorado State University, Fort Collins\n",
        "\n",
        "<Danish.Gufran@colostate.edu>\n",
        "<Jadon.Johnson@colostate.edu>\n",
        "<Isaac.Blair@colostate.edu>\n",
        "<Sudeep@colostate.edu>\n",
        "\n",
        "Title - Data Augmentation Methods for Wi-Fi RSS Fingerprinting Based Indoor Localization.\n",
        "\n",
        "Citation :\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT8GeBUZ_f9E",
        "outputId": "c8093581-3ee3-48e7-b379-0799410b0d58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'RSS_Database' already exists and is not an empty directory.\n",
            "fatal: destination path 'EPIC_Lab_Data' already exists and is not an empty directory.\n",
            "fatal: destination path 'heterogeneous-rssi-indoor-nav' already exists and is not an empty directory.\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.1)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: keras-multi-head in /usr/local/lib/python3.10/dist-packages (0.29.0)\n",
            "Requirement already satisfied: keras-self-attention==0.51.0 in /usr/local/lib/python3.10/dist-packages (from keras-multi-head) (0.51.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-self-attention==0.51.0->keras-multi-head) (1.26.4)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Requirement already satisfied: cleverhans in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.10/dist-packages (from cleverhans) (1.3.7)\n",
            "Requirement already satisfied: pycodestyle in /usr/local/lib/python3.10/dist-packages (from cleverhans) (2.12.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from cleverhans) (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from cleverhans) (3.7.1)\n",
            "Requirement already satisfied: mnist in /usr/local/lib/python3.10/dist-packages (from cleverhans) (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from cleverhans) (1.26.4)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.10/dist-packages (from cleverhans) (0.24.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from cleverhans) (1.4.2)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (from cleverhans) (1.13)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from cleverhans) (1.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from cleverhans) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cleverhans) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cleverhans) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cleverhans) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cleverhans) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cleverhans) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cleverhans) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cleverhans) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cleverhans) (2.8.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability->cleverhans) (2.2.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability->cleverhans) (0.6.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability->cleverhans) (0.1.8)\n"
          ]
        }
      ],
      "source": [
        "# !rm -rf maril\n",
        "try:\n",
        "  !git clone https://github.com/danishgufran/RSS_Database.git\n",
        "  !git clone https://github.com/danishgufran/EPIC_Lab_Data.git\n",
        "  !git clone https://github.com/EPIC-CSU/heterogeneous-rssi-indoor-nav.git\n",
        "  !pip install tensorflow-addons\n",
        "  !pip install keras-multi-head\n",
        "  !pip install catboost\n",
        "  !pip install cleverhans\n",
        "\n",
        "except:\n",
        "  from git import Repo  # pip install gitpython\n",
        "  Repo.clone_from(\"https://github.com/danishgufran/RSS_Database.git\")\n",
        "  Repo.clone_from(\"https://github.com/danishgufran/EPIC_Lab_Data.git\")\n",
        "  Repo.clone_from(\"https://github.com/EPIC-CSU/heterogeneous-rssi-indoor-nav.git\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ixhfUhNmSynl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "import io\n",
        "from contextlib import redirect_stdout\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import copy\n",
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D , LSTM, Attention\n",
        "from tensorflow.keras.losses import *\n",
        "from tensorflow.keras.optimizers import*\n",
        "import random as random\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import pandas as pd\n",
        "\n",
        "import RSS_Database.Stone_Seth.Seth\n",
        "from RSS_Database.Stone_Seth.Seth import fetch_seth, Devices, Floorplan, get_mac_ids\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from EPIC_Lab_Data.data import Devices, Floorplan, build_dataset\n",
        "from EPIC_Lab_Data.helpers import compute_distances\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import lightgbm as lgb\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import numpy as np\n",
        "\n",
        "import logging\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import LayerNormalization\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import Loss\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import svm\n",
        "import xgboost as xgb\n",
        "\n",
        "from EPIC_Lab_Data.helpers import split_frame, compute_distances\n",
        "from EPIC_Lab_Data.data import build_dataset\n",
        "from EPIC_Lab_Data.Maril.MultiHeadAttentionAddon import MultiHeadAttentionAddon\n",
        "\n",
        "from cleverhans.tf2.attacks.momentum_iterative_method import momentum_iterative_method\n",
        "from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method\n",
        "from cleverhans.tf2.attacks.projected_gradient_descent import projected_gradient_descent\n",
        "from cleverhans.tf2.attacks.momentum_iterative_method import momentum_iterative_method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fZCKI2YL_5Pk"
      },
      "outputs": [],
      "source": [
        "def train_data(itr,dev, floorplan):\n",
        "    # dfs is a list of dataframes\n",
        "# meta is a dataframe with meta data\n",
        "\n",
        "#getting train data\n",
        "\n",
        "#     train_fp, train_meta = fetch_seth(\n",
        "#     dev,\n",
        "#     str(floorplan),\n",
        "#     ci = int(itr),\n",
        "#     base_path=\"RSS_DataEPIC_Lab_Data/Data/train/\"  # <-- this would be 'seth/temp/clean' from outside this dir\n",
        "# )\n",
        "    train_fp, _, macs, lbl2cord = build_dataset(\n",
        "        dev,\n",
        "        str(floorplan),\n",
        "    )\n",
        "    train_fp = train_fp.sample(frac=1).reset_index(drop=True)\n",
        "    train_aps = get_mac_ids(train_fp.columns)\n",
        "    train_x = train_fp[train_aps].values\n",
        "    # train_x = (train_x + 100)/100\n",
        "    train_y = (train_fp[\"label\"]).values\n",
        "    return train_x, train_y, train_aps\n",
        "\n",
        "def test_data(itr, train_aps, dev, floorplan):\n",
        "    #getting test data\n",
        "#     test_fp, test_meta = fetch_seth(\n",
        "#     dev ,\n",
        "#     str(floorplan),\n",
        "#     ci = itr,\n",
        "#     base_path=\"RSS_DataEPIC_Lab_Data/Data/test/\"  # <-- this would be 'seth/temp/clean' from outside this dir\n",
        "# )\n",
        "    train_df, test_fp, macs_test, lbl2cords = build_dataset(\n",
        "          dev,\n",
        "          str(floorplan)\n",
        "      )\n",
        "    test_aps = get_mac_ids(test_fp.columns)\n",
        "    missing_aps = list(set(train_aps)-set(test_aps))\n",
        "    missing_df = pd.DataFrame(0, index=test_fp.index, columns=missing_aps)\n",
        "    test_fp = pd.concat([test_fp, missing_df], axis=1)\n",
        "    test_x = test_fp[train_aps].values\n",
        "    test_x = (test_x + 100)/100\n",
        "    test_y = (test_fp[\"label\"]).values\n",
        "\n",
        "    # test_x = (test_x + 100)/100\n",
        "\n",
        "\n",
        "    return np.array(test_x), test_y\n",
        "\n",
        "def temp_train_data(dev, floorplan, ci_val):\n",
        "    # dfs is a list of dataframes\n",
        "# meta is a dataframe with meta data\n",
        "\n",
        "#getting train data\n",
        "\n",
        "    train_fp, train_meta = fetch_seth(\n",
        "    dev,\n",
        "    str(floorplan),\n",
        "    ci = ci_val,\n",
        "    base_path=\"RSS_Database/Stone_Seth/temp/clean/\"  # <-- this would be 'seth/temp/clean' from outside this dir\n",
        ")\n",
        "    # train_fp, _, macs, lbl2cord = build_dataset(\n",
        "    #     dev,\n",
        "    #     str(floorplan),\n",
        "    # )\n",
        "    train_fp = train_fp.sample(frac=1).reset_index(drop=True)\n",
        "    train_aps = get_mac_ids(train_fp.columns)\n",
        "    train_x = train_fp[train_aps].values\n",
        "    train_x = (train_x + 100)/100\n",
        "    train_y = (train_fp[\"label\"]).values\n",
        "    return train_x, train_y, train_aps\n",
        "def temp_test_data(train_aps, dev, floorplan, ci_val):\n",
        "    #getting test data\n",
        "    test_fp, test_meta = fetch_seth(\n",
        "    str(dev) ,\n",
        "    str(floorplan),\n",
        "    ci = ci_val,\n",
        "    base_path=\"RSS_Database/Stone_Seth/temp/clean/\"  # <-- this would be 'seth/temp/clean' from outside this dir\n",
        ")\n",
        "    # train_df, test_fp, macs_test, lbl2cords = build_dataset(\n",
        "    #       dev,\n",
        "    #       str(floorplan)\n",
        "    #   )\n",
        "    test_aps = get_mac_ids(test_fp.columns)\n",
        "    missing_aps = list(set(train_aps)-set(test_aps))\n",
        "    test_fp[missing_aps] = 0\n",
        "    test_x = test_fp[train_aps].values\n",
        "    test_x = (test_x + 100)/100\n",
        "    test_y = (test_fp[\"label\"]).values\n",
        "    return test_x, test_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nplIyqc7wK6Y"
      },
      "outputs": [],
      "source": [
        "def stacked_sae(input, train_x, train_y, eph):\n",
        "  print(\"\\n Training Stacked SAE... \\n\")\n",
        "  h1 = int(input - input*0.3)\n",
        "  h2 = int(h1 - h1*0.3)\n",
        "  h3 = int(h2 - h2*0.3)\n",
        "  h4 = int(h3 - h3*0.3)\n",
        "  #print(input,h1,h2,h3, h4)\n",
        "  # AE -1\n",
        "  input_img = keras.layers.Input(shape = (input, ))\n",
        "  GN = keras.layers.GaussianNoise(0.)(input_img)\n",
        "  distorted_input1 = Dropout(.1)(GN)\n",
        "  encoded1 = Dense(h1, activation = 'gelu')(distorted_input1)\n",
        "  decoded1 = Dense(input, activation = 'sigmoid')(encoded1)\n",
        "\n",
        "  autoencoder1 = keras.models.Model(inputs = input_img, outputs = decoded1)\n",
        "  encoder1 = keras.models.Model(inputs = input_img, outputs = encoded1)\n",
        "\n",
        "  # AE -2\n",
        "  encoded1_input = keras.layers.Input(shape = (h1,))\n",
        "  GN1 = keras.layers.GaussianNoise(0.)(encoded1_input)\n",
        "  distorted_input2 = Dropout(.10)(GN1)\n",
        "  encoded2 = Dense(h2, activation = 'gelu')(distorted_input2)\n",
        "  decoded2 = Dense(h1, activation = 'sigmoid')(encoded2)\n",
        "\n",
        "  autoencoder2 = tf.keras.Model(inputs = encoded1_input, outputs = decoded2)\n",
        "  encoder2 = tf.keras.Model(inputs = encoded1_input, outputs = encoded2)\n",
        "\n",
        "  # AE -3\n",
        "  encoded2_input = keras.layers.Input(shape = (h2,))\n",
        "  GN2 = keras.layers.GaussianNoise(0.)(encoded2_input)\n",
        "  distorted_input3 = Dropout(.10)(GN2)\n",
        "  encoded3 = Dense(h3, activation = 'gelu')(distorted_input3)\n",
        "  decoded3 = Dense(h2, activation = 'sigmoid')(encoded3)\n",
        "\n",
        "  autoencoder3 = tf.keras.Model(inputs = encoded2_input, outputs = decoded3)\n",
        "  encoder3 = tf.keras.Model(inputs = encoded2_input, outputs = encoded3)\n",
        "\n",
        "  # AE -4\n",
        "  encoded3_input = keras.layers.Input(shape = (h3,))\n",
        "  GN3 = keras.layers.GaussianNoise(0.)(encoded3_input)\n",
        "  distorted_input4 = Dropout(.10)(GN3)\n",
        "  encoded4 = Dense(h4, activation = 'gelu')(distorted_input4)\n",
        "  decoded4 = Dense(h3, activation = 'sigmoid')(encoded4)\n",
        "\n",
        "  autoencoder4 = tf.keras.Model(inputs = encoded3_input, outputs = decoded4)\n",
        "  encoder4 = tf.keras.Model(inputs = encoded3_input, outputs = encoded4)\n",
        "  # Final AE\n",
        "  encoded1_da = Dense(h1, activation = 'sigmoid')(input_img)\n",
        "  encoded2_da = Dense(h2, activation = 'sigmoid')(encoded1_da)\n",
        "  encoded3_da = Dense(h3, activation = 'sigmoid')(encoded2_da)\n",
        "  encoded4_da = Dense(h4, activation = 'sigmoid')(encoded3_da)\n",
        "  decoded4_da = Dense(h3, activation = 'sigmoid')(encoded4_da)\n",
        "  decoded3_da = Dense(h2, activation = 'sigmoid')(decoded4_da)\n",
        "  decoded2_da = Dense(h1, activation = 'sigmoid')(decoded3_da)\n",
        "  decoded1_da = Dense(input, activation = 'sigmoid')(decoded2_da)\n",
        "\n",
        "  deep_autoencoder = tf.keras.Model(inputs = input_img, outputs = decoded1_da)\n",
        "  #compile\n",
        "  sgd1 = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "  sgd2 = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "  sgd3 = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "  sgd4 = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "\n",
        "  sgdD = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "\n",
        "  autoencoder1.compile(loss='mse', optimizer = sgd1)\n",
        "  autoencoder2.compile(loss='mse', optimizer = sgd2)\n",
        "  autoencoder3.compile(loss='mse', optimizer = sgd3)\n",
        "  autoencoder4.compile(loss='mse', optimizer = sgd4)\n",
        "\n",
        "  encoder1.compile(loss='mse', optimizer = sgd1)\n",
        "  encoder2.compile(loss='mse', optimizer = sgd1)\n",
        "  encoder3.compile(loss='mse', optimizer = sgd1)\n",
        "  encoder4.compile(loss='mse', optimizer = sgd1)\n",
        "\n",
        "  deep_autoencoder.compile(loss='mse', optimizer = sgdD)\n",
        "  # fit ae 1\n",
        "  autoencoder1.fit(train_x, train_x,\n",
        "                epochs = eph,\n",
        "                validation_split = 0.0020,\n",
        "                shuffle = False, verbose =0,\n",
        "                callbacks=[\n",
        "                keras.callbacks.EarlyStopping(patience=200, restore_best_weights=True)])\n",
        "  first_layer_code = encoder1.predict(train_x)\n",
        "  #fit ae 2\n",
        "  autoencoder2.fit(first_layer_code, first_layer_code,\n",
        "                epochs = eph,\n",
        "                validation_split = 0.0020,\n",
        "                shuffle = False, verbose =0,\n",
        "                callbacks=[\n",
        "                keras.callbacks.EarlyStopping(patience=200, restore_best_weights=True)])\n",
        "  second_layer_code = encoder2.predict(first_layer_code)\n",
        "  #fit ae 3\n",
        "  autoencoder3.fit(second_layer_code, second_layer_code,\n",
        "               epochs = eph,\n",
        "               validation_split = 0.0020,\n",
        "               shuffle = False, verbose =0,\n",
        "                callbacks=[\n",
        "                keras.callbacks.EarlyStopping(patience=200, restore_best_weights=True)])\n",
        "  third_layer_code = encoder3.predict(second_layer_code)\n",
        "    #fit ae 4\n",
        "  autoencoder4.fit(third_layer_code, third_layer_code,\n",
        "               epochs = eph,\n",
        "               validation_split = 0.0020,\n",
        "               shuffle = False, verbose =0,\n",
        "                callbacks=[\n",
        "                keras.callbacks.EarlyStopping(patience=2000, restore_best_weights=True)])\n",
        "  fourth_layer_code = encoder4.predict(third_layer_code)\n",
        "  # Setting the weights of the deep autoencoder\n",
        "  deep_autoencoder.layers[1].set_weights(encoder1.layers[-1].get_weights()) # first dense layer\n",
        "\n",
        "  deep_autoencoder.layers[2].set_weights(encoder2.layers[-1].get_weights()) # second dense layer\n",
        "\n",
        "  deep_autoencoder.layers[3].set_weights(encoder3.layers[-1].get_weights()) # thrird dense layer\n",
        "\n",
        "  deep_autoencoder.layers[4].set_weights(encoder4.layers[-1].get_weights()) # fourth dense layer\n",
        "\n",
        "  # deep_autoencoder.layers[5].set_weights(autoencoder4.layers[-1].get_weights()) # fourth dense layer\n",
        "\n",
        "  deep_autoencoder.layers[6].set_weights(autoencoder3.layers[-1].get_weights()) # first decoder\n",
        "  deep_autoencoder.layers[7].set_weights(autoencoder2.layers[-1].get_weights()) # second decoder\n",
        "  deep_autoencoder.layers[8].set_weights(autoencoder1.layers[-1].get_weights()) # third decoder\n",
        "\n",
        "  deep_autoencoder.fit(train_x, train_x,\n",
        "                epochs = eph,\n",
        "                validation_split = 0.0020,\n",
        "                shuffle = False,\n",
        "                verbose =0,\n",
        "                callbacks=[keras.callbacks.EarlyStopping(patience=500, restore_best_weights=True)])\n",
        "\n",
        "  sae_fingerprint = []\n",
        "\n",
        "  for fingerprint in train_x:\n",
        "    fingerprint = fingerprint.reshape(1, -1)\n",
        "    sae_train_x = deep_autoencoder.predict(fingerprint, verbose = 0)\n",
        "    sae_train_x = np.array(sae_train_x)\n",
        "    rounded_data = np.round(sae_train_x[0], 2)  # Round to 2 decimal places\n",
        "    sae_fingerprint.append(rounded_data)\n",
        "\n",
        "  return np.array(sae_fingerprint), train_y, deep_autoencoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "06D7GGvechAJ"
      },
      "outputs": [],
      "source": [
        "def sae(input_dim, train_x, train_y, epochs):\n",
        "    print(\"\\n Training Standard Autoencoder... \\n\")\n",
        "\n",
        "    # Define the architecture\n",
        "    h1 = int(input_dim - input_dim * 0.3)\n",
        "    h2 = int(h1 - h1 * 0.3)\n",
        "    h3 = int(h2 - h2 * 0.3)\n",
        "    h4 = int(h3 - h3 * 0.3)\n",
        "\n",
        "    # Input layer\n",
        "    input_img = keras.layers.Input(shape=(input_dim,))\n",
        "\n",
        "    # Encoder\n",
        "    encoded = Dense(h1, activation='gelu')(input_img)\n",
        "    encoded = Dense(h2, activation='gelu')(encoded)\n",
        "    encoded = Dense(h3, activation='gelu')(encoded)\n",
        "    encoded = Dense(h4, activation='gelu')(encoded)\n",
        "\n",
        "    # Decoder\n",
        "    decoded = Dense(h3, activation='gelu')(encoded)\n",
        "    decoded = Dense(h2, activation='gelu')(decoded)\n",
        "    decoded = Dense(h1, activation='gelu')(decoded)\n",
        "    decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
        "\n",
        "    # Autoencoder model\n",
        "    autoencoder = keras.models.Model(inputs=input_img, outputs=decoded)\n",
        "\n",
        "    # Compile the model\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    # Train the autoencoder\n",
        "    autoencoder.fit(train_x, train_x,\n",
        "                    epochs=epochs,\n",
        "                    validation_split=0.0020,\n",
        "                    shuffle=True,\n",
        "                    verbose=0,\n",
        "                    callbacks=[keras.callbacks.EarlyStopping(patience=200, restore_best_weights=True)])\n",
        "\n",
        "    # Encode the input data to generate the final feature representation\n",
        "    encoded_data = autoencoder.predict(train_x)\n",
        "\n",
        "    # Optionally round the encoded data\n",
        "    sae_fingerprint = np.round(encoded_data, 2)\n",
        "\n",
        "    return sae_fingerprint, train_y, autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "kCgHc1xea8e4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Generate augmented data using GAN\n",
        "\n",
        "def build_generator(noise_dim, output_dim):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(noise_dim, input_dim=noise_dim, activation='relu'))\n",
        "    # model.add(layers.Dense(64, activation='tanh'))\n",
        "    model.add(layers.Dense(int(noise_dim), activation='relu'))\n",
        "    model.add(layers.Dense(output_dim, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# Discriminator Network\n",
        "def build_discriminator(input_dim):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(128, input_dim=input_dim, activation='relu'))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    # model.add(layers.Dense(32, activation='tanh'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "def train_gan(train_x, train_y, noise_dim, batch_size, epochs):\n",
        "    input_dim = train_x.shape[1]\n",
        "    generator = build_generator(noise_dim, input_dim)\n",
        "    discriminator = build_discriminator(input_dim)\n",
        "\n",
        "    # Compile Discriminator\n",
        "    discriminator.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Combined model (Generator + Discriminator)\n",
        "    discriminator.trainable = False\n",
        "    gan_input = layers.Input(shape=(noise_dim,))\n",
        "    generated_data = generator(gan_input)\n",
        "    gan_output = discriminator(generated_data)\n",
        "    gan = models.Model(gan_input, gan_output)\n",
        "    gan.compile(optimizer=optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy')\n",
        "\n",
        "    # Training the GAN\n",
        "    print(\"\\n Training GAN... \\n\")\n",
        "    for epoch in range(epochs):\n",
        "        for _ in range(len(train_x) // batch_size):\n",
        "            # Generate fake data\n",
        "            noise = np.random.normal(0, 1, (batch_size, noise_dim))\n",
        "            generated_data = generator.predict(noise, verbose=0)\n",
        "\n",
        "            # Select a random batch of real data\n",
        "            idx = np.random.randint(0, train_x.shape[0], batch_size)\n",
        "            real_data = train_x[idx]\n",
        "\n",
        "            # Labels for real and fake data\n",
        "            real_labels = np.ones((batch_size, 1))\n",
        "            fake_labels = np.zeros((batch_size, 1))\n",
        "\n",
        "            # Train the Discriminator\n",
        "            d_loss_real = discriminator.train_on_batch(real_data, real_labels)\n",
        "            d_loss_fake = discriminator.train_on_batch(generated_data, fake_labels)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # Train the Generator\n",
        "            noise = np.random.normal(0, 1, (batch_size, noise_dim))\n",
        "            valid_y = np.ones((batch_size, 1))\n",
        "            g_loss = gan.train_on_batch(noise, valid_y)\n",
        "\n",
        "        # Uncomment below for training info (verbose = 1)\n",
        "        # if epoch :\n",
        "        #     print(f'Epoch {epoch}, D Loss: {d_loss[0]:.4f}, D Acc.: {100*d_loss[1]:.2f}%')\n",
        "\n",
        "    # Generate augmented data\n",
        "    gan_x = []\n",
        "    gan_y = []\n",
        "    for i in range(len(train_x)):\n",
        "        noise = np.random.normal(0, 1, (1, noise_dim))\n",
        "        generated_data = generator.predict(noise, verbose=0)\n",
        "        rounded_data = np.round(generated_data[0], 2)  # Round to 2 decimal places\n",
        "        gan_x.append(rounded_data)\n",
        "        gan_y.append(train_y[i])  # Assuming RP class remains the same\n",
        "\n",
        "    sorted_indices = np.argsort(train_y)\n",
        "    gan_x = np.array(gan_x)[sorted_indices]\n",
        "    gan_y = np.array(gan_y)[sorted_indices]\n",
        "    return gan_x, gan_y, generator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lRHNuaXH4LbK"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_fgsm(train_x, train_y, epsilon, model):\n",
        "    # Convert train_x and train_y to TensorFlow tensors\n",
        "    train_x = tf.convert_to_tensor(train_x, dtype=tf.float32)\n",
        "    train_y = tf.convert_to_tensor(train_y, dtype=tf.float32)\n",
        "\n",
        "    # Ensure model is compiled if not already\n",
        "    if not model.compiled_loss:\n",
        "        model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "\n",
        "    # Generate FGSM adversarial samples\n",
        "    fgsm_x = fast_gradient_method(model_fn=model, x=train_x, eps=epsilon, norm=np.inf)\n",
        "\n",
        "    return np.array(fgsm_x), train_y\n",
        "\n",
        "\n",
        "def train_pgd(train_x, train_y, epsilon, model, alpha=0.01, num_iterations=40):\n",
        "    # Convert train_x and train_y to TensorFlow tensors\n",
        "    train_x = tf.convert_to_tensor(train_x, dtype=tf.float32)\n",
        "    train_y = tf.convert_to_tensor(train_y, dtype=tf.float32)\n",
        "\n",
        "    # Ensure model is compiled if not already\n",
        "    if not model.compiled_loss:\n",
        "        model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "\n",
        "    # Generate PGD adversarial samples\n",
        "    pgd_x = projected_gradient_descent(model_fn=model, x=train_x, eps=epsilon, eps_iter=alpha, nb_iter=num_iterations, norm=np.inf)\n",
        "\n",
        "    return np.array(pgd_x), train_y\n",
        "\n",
        "\n",
        "def train_mim(train_x, train_y, epsilon, model, alpha=0.01, num_iterations=40):\n",
        "    # Convert train_x and train_y to TensorFlow tensors\n",
        "    train_x = tf.convert_to_tensor(train_x, dtype=tf.float32)\n",
        "    train_y = tf.convert_to_tensor(train_y, dtype=tf.float32)\n",
        "\n",
        "    # Ensure model is compiled if not already\n",
        "    if not model.compiled_loss:\n",
        "        model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "\n",
        "    # Generate MIM adversarial samples\n",
        "    mim_x = momentum_iterative_method(model_fn=model, x=train_x, eps=epsilon, eps_iter=alpha, nb_iter=num_iterations, norm=np.inf)\n",
        "\n",
        "    return np.array(mim_x), train_y\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "TmaxJOtloQeN"
      },
      "outputs": [],
      "source": [
        "def model_params(model, save_name):\n",
        "  # The summary can be commented to not print on console [Will still save in .txt]\n",
        "    print(f'\\n*** Model Summary : {save_name} ***\\n')\n",
        "    model.summary()\n",
        "    with open(f'{save_name}.txt', 'w') as f:\n",
        "        model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
        "        f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "-1r8RIW6LPh1"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Add functions for the models here :\n",
        "\n",
        "# Add functions for :\n",
        "# KNN, GPC, SVM, RF, CatBoost, XgBoost, LightGBM, MLP, DNN, CNN, Attention, Transformer, VIT\n",
        "\n",
        "[1] Feel free to pass any arguments as input to the functions.\n",
        "[2] Each function must always return the trained model #return model\n",
        "[3] The DNN model is NOT optimized - you need to fix it\n",
        "[4] Play with the hyper-parameters to get the best trained model (you can change things as you seem fit)\n",
        "[5] You can use grid search methods like : NAS, Keras Tuner, Auto Keras and so on, to find the best hyper parameters\n",
        "    Note : It would be best if you open a new cell to test out your grid search method on the ML model and once you find the best model configuration you can insert that to the main run.\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "def train_DNN(train_x, train_y, ep, batch_size=128):\n",
        "    print('Training DNN Classifier \\n')\n",
        "    # Build the DNN model\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(128, activation='gelu',input_shape=train_x.shape[1:]))\n",
        "    # model.add(tf.keras.layers.Dense(128, activation='gelu'))\n",
        "\n",
        "    model.add(tf.keras.layers.GaussianNoise(0.15))\n",
        "    model.add(tf.keras.layers.Dropout(0.15))\n",
        "\n",
        "    # model.add(tf.keras.layers.Dense(64, activation='gelu'))\n",
        "    # model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "    # model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(int(max(train_y)+1), activation='sigmoid'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate = 0.01),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(train_x,train_y,\n",
        "                epochs = ep,\n",
        "                shuffle = True,\n",
        "                verbose = 1)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Code Instructions :\n",
        "\n",
        "[1] Create new functions (in the cell above) to train all ML models (I have added research papers for each model for you to reference)\n",
        "        Please Note : The research papers are for reference to see how the particular model is trained. Look at the hyper-parameters the paper mentions and start with those, after which you can fine tune them.\n",
        "        These are the model -> KNN, GPC, SVM, RF, CatBoost, XgBoost, LightGBM, MLP, DNN, CNN, Attention, Transformer, VIT\n",
        "[2] Once the model functions are created call them in the cell below look out for '# [JJ] [IB] :' for additional information\n",
        "[3] Next update the model_name variable with the name of the new model\n",
        "[4] Use the new model name to add subsequent 'if' conditions for all training conditions\n",
        "[5] Now you need to fine tune the hyper-parameters in your new model to get the best trained model.\n",
        "    Here is how you can vaidate your model:\n",
        "    [5.A] Monitor the the accuracy and loss functions during training (accuracy must increase and loss must decrease)\n",
        "    [5.B] No need to change anything in SAE, Stacked SAE, GAN, FGSM, PGD, and MIM - Only update the new model functions\n",
        "    [5.C] Make sure to add all import and API calls in the 3rd cell of this notebook\n",
        "    [5.D] Make sure to add any pip installs (if needed) in the second cell of this notebook\n",
        "    [5.E] Finally, check the summary (CSV) files that gets generated after inference to see the average error for each case, ideally we need lower errors for all or MOST cases\n",
        "          One way to evaluate if your model is trained well is to see if it atleast (pay attention here) has lower errors for the conditions it was trained on\n",
        "          E.g, If the model was trained only on ORIGINAL data it must show low errors for inference on original data (across all devices) : This is the bare minimum, if other inferences like FGSM and so on show low errors as well then you have a great model (You need to aim to get this)\n",
        "          E.g, If the model was trained only on ORIGINAL + FGSM data it must show low errors for inference on original and FGSM data (across all devices)\n",
        "    [5.F] At the end you will notice that the script downloads a .zip file with the trained model (.keras), model summary (.txt), and inference output (.csv) - also another .csv file with the summary (average errors across all inference conditions). You will report that .zip (assuming with the best hyper-parameters of the model) to me.\n",
        "[6] Before you submit the .zip file and the updated .ipynb (with your additions to the ML model) make sure your team sits together and merge all changes into 1 .ipynb (so that i have the most recent notebook with changes from everyone)\n",
        "    [6.A] During the merge make sure the script has no errors and the results are satisfactory.\n",
        "    [6.B] Take this oppurtunity to evaluate each others changes to check if the results are satisfactory. Only report data to me when both of you are convinced with the results. I will do one last check before we move on to Phase 4 (As discussed in our meetings).\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "oui9V7qxwNs1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "42c3e7b0-9013-4576-f7a1-cdd64befee2f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Code Instructions :\\n\\n[1] Create new functions (in the cell above) to train all ML models (I have added research papers for each model for you to reference)\\n        Please Note : The research papers are for reference to see how the particular model is trained. Look at the hyper-parameters the paper mentions and start with those, after which you can fine tune them.\\n        These are the model -> KNN, GPC, SVM, RF, CatBoost, XgBoost, LightGBM, MLP, DNN, CNN, Attention, Transformer, VIT\\n[2] Once the model functions are created call them in the cell below look out for '[JJ] [IB] :' for additional information\\n[3] Next update the model_name variable with the name of the new model\\n[4] Use the new model name to add subsequent 'if' conditions for all training conditions\\n[5] Now you need to fine tune the hyper-parameters in your new model to get the best trained model.\\n    Here is how you can vaidate your model:\\n    [5.A] Monitor the the accuracy and loss functions during training (accuracy must increase and loss must decrease)\\n    [5.B] No need to change anything in SAE, Stacked SAE, GAN, FGSM, PGD, and MIM - Only update the new model functions\\n    [5.C] Make sure to add all import and API calls in the 3rd cell of this notebook\\n    [5.D] Make sure to add any pip installs (if needed) in the second cell of this notebook\\n    [5.E] Finally, check the summary (CSV) files that gets generated after inference to see the average error for each case, ideally we need lower errors for all or MOST cases\\n          One way to evaluate if your model is trained well is to see if it atleast (pay attention here) has lower errors for the conditions it was trained on\\n          E.g, If the model was trained only on ORIGINAL data it must show low errors for inference on original data (across all devices) : This is the bare minimum, if other inferences like FGSM and so on show low errors as well then you have a great model (You need to aim to get this)\\n          E.g, If the model was trained only on ORIGINAL + FGSM data it must show low errors for inference on original and FGSM data (across all devices)\\n    [5.F] At the end you will notice that the script downloads a .zip file with the trained model (.keras), model summary (.txt), and inference output (.csv) - also another .csv file with the summary (average errors across all inference conditions). You will report that .zip (assuming with the best hyper-parameters of the model) to me.\\n[6] Before you submit the .zip file and the updated .ipynb (with your additions to the ML model) make sureyour team sits together and merge all changes into 1 .ipynb (so that i have the most recent notebook with changes from everyone)\\n    [6.A] During the merge make sure the script has no errors and the results are satisfactory.\\n    [6.B] Take this oppurtunity to evaluate each others changes to check if the results are satisfactory. Only report data to me when both of you are convinced with the results. I will do one last check before we move on to Phase 4 (As discussed in our meetings).\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Here are some research papers for you to get started with. Look at the hyper-parameters the paper proposes and start with those and then use other sources (internet) to learn the uses of different hyper-parameters and start experimenting on them.\n",
        "You can also create a temporary cell somewhere below to test your model before you run it in the main cell.\n",
        "The main cell may run for a couple of hours, so make sure there are no errors as you go.\n",
        "\n",
        "Here are the list of research papers:\n",
        "\n",
        "KNN [1], GPC [2], SVM [3], RF [4], CatBoost [5], XgBoost [6], LightGBM [7], MLP [8], DNN [9], CNN [10], Attention [11], Transformer [12], VIT [13]\n",
        "\n",
        "[1] KNN : https://ieeexplore.ieee.org/abstract/document/7386596\n",
        "\n",
        "[2] GPC : https://ieeexplore.ieee.org/abstract/document/8767421\n",
        "\n",
        "[3] SVM : https://ieeexplore.ieee.org/abstract/document/7986446\n",
        "\n",
        "[4] RF : https://link.springer.com/article/10.1007/s11277-020-07977-w\n",
        "\n",
        "[5] CatBoost : https://ieeexplore.ieee.org/abstract/document/10130598\n",
        "\n",
        "[6] XgBoost : https://www.mdpi.com/1424-8220/22/17/6629\n",
        "\n",
        "[7] LightGBM : https://www.mdpi.com/1424-8220/21/8/2722\n",
        "\n",
        "[8] MLP : https://ieeexplore.ieee.org/abstract/document/9606541\n",
        "\n",
        "[9] DNN : https://dl.acm.org/doi/full/10.1145/3607919\n",
        "\n",
        "[10] CNN : https://ieeexplore.ieee.org/abstract/document/9060340\n",
        "\n",
        "[11] Attention : https://ieeexplore.ieee.org/abstract/document/9918120\n",
        "\n",
        "[12] Transformer : https://ieeexplore.ieee.org/abstract/document/9923937\n",
        "\n",
        "[13] VIT : https://ieeexplore.ieee.org/abstract/document/10247684\n",
        "\n",
        "[13] VIT : https://arxiv.org/abs/2010.11929\n",
        "'''\n",
        "\n",
        "# NAS, Keras tuner, auto keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "qeoT9hUT7DI3",
        "outputId": "c269fef1-b9d2-4d82-af2a-0b07e3788965"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nHere are some research papers for you to get started with. Look at the hyper-parameters the paper proposes and start with those and then use other sources (internet) to learn the uses of different hyper-parameters and start experimenting on them.\\nYou can also create a temporary cell somewhere below to test your model before you run it in the main cell.\\nThe main cell may run for a couple of hours, so make sure there are no errors as you go.\\n\\nHere are the list of research papers:\\n\\nKNN [1], GPC [2], SVM [3], RF [4], CatBoost [5], XgBoost [6], LightGBM [7], MLP [8], DNN [9], CNN [10], Attention [11], Transformer [12], VIT [13]\\n\\n[1] KNN : https://ieeexplore.ieee.org/abstract/document/7386596\\n\\n[2] GPC : https://ieeexplore.ieee.org/abstract/document/8767421\\n\\n[3] SVM : https://ieeexplore.ieee.org/abstract/document/7986446\\n\\n[4] RF : https://link.springer.com/article/10.1007/s11277-020-07977-w\\n\\n[5] CatBoost : https://ieeexplore.ieee.org/abstract/document/10130598\\n\\n[6] XgBoost : https://www.mdpi.com/1424-8220/22/17/6629\\n\\n[7] LightGBM : https://www.mdpi.com/1424-8220/21/8/2722\\n\\n[8] MLP : https://ieeexplore.ieee.org/abstract/document/9606541\\n\\n[9] DNN : https://dl.acm.org/doi/full/10.1145/3607919\\n\\n[10] CNN : https://ieeexplore.ieee.org/abstract/document/9060340\\n\\n[11] Attention : https://ieeexplore.ieee.org/abstract/document/9918120\\n\\n[12] Transformer : https://ieeexplore.ieee.org/abstract/document/9923937\\n\\n[13] VIT : https://ieeexplore.ieee.org/abstract/document/10247684\\n\\n[13] VIT : https://arxiv.org/abs/2010.11929\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "o6VgGIGYS7BG",
        "outputId": "d6e273ea-044d-4ed4-d9d5-10d672539ecb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Train dev -> OP3   flp -> engr0 \n",
            "\n",
            "Training on Original RSS - Train Device : OP3  Floorplan : engr0 \n",
            "\n",
            "\n",
            "************ Training Model : ORIGINAL engr0 + DNN ************\n",
            "\n",
            "Training DNN Classifier \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 149ms/step - accuracy: 9.1178e-04 - loss: 12.9599\n",
            "\n",
            "*** Model Summary : ORIGINAL_DNN_OP3_eps_0_engr0 ***\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_19\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_19\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " dense_98 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                           \u001b[38;5;34m21,248\u001b[0m \n",
              "\n",
              " gaussian_noise_23 (\u001b[38;5;33mGaussianNoise\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_23 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_99 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m)                             \u001b[38;5;34m7,869\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " dense_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">21,248</span> \n",
              "\n",
              " gaussian_noise_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">7,869</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m87,353\u001b[0m (341.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">87,353</span> (341.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,117\u001b[0m (113.74 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,117</span> (113.74 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m58,236\u001b[0m (227.49 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">58,236</span> (227.49 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ORIGINAL Complete .... \n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training on SAE  - Train Device : OP3  Floorplan : engr0 \n",
            "\n",
            "\n",
            " Training Standard Autoencoder... \n",
            "\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\n",
            "*** Model Summary : SAE_OP3_engr0 ***\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_235\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_235\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer_33 (\u001b[38;5;33mInputLayer\u001b[0m)           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m165\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_100 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115\u001b[0m)                           \u001b[38;5;34m19,090\u001b[0m \n",
              "\n",
              " dense_101 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                             \u001b[38;5;34m9,280\u001b[0m \n",
              "\n",
              " dense_102 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)                             \u001b[38;5;34m4,536\u001b[0m \n",
              "\n",
              " dense_103 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)                             \u001b[38;5;34m2,223\u001b[0m \n",
              "\n",
              " dense_104 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)                             \u001b[38;5;34m2,240\u001b[0m \n",
              "\n",
              " dense_105 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                             \u001b[38;5;34m4,560\u001b[0m \n",
              "\n",
              " dense_106 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115\u001b[0m)                            \u001b[38;5;34m9,315\u001b[0m \n",
              "\n",
              " dense_107 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m165\u001b[0m)                           \u001b[38;5;34m19,140\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " input_layer_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">19,090</span> \n",
              "\n",
              " dense_101 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">9,280</span> \n",
              "\n",
              " dense_102 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">4,536</span> \n",
              "\n",
              " dense_103 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,223</span> \n",
              "\n",
              " dense_104 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,240</span> \n",
              "\n",
              " dense_105 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">4,560</span> \n",
              "\n",
              " dense_106 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">9,315</span> \n",
              "\n",
              " dense_107 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">19,140</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m211,154\u001b[0m (824.82 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">211,154</span> (824.82 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m70,384\u001b[0m (274.94 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,384</span> (274.94 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m140,770\u001b[0m (549.89 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">140,770</span> (549.89 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "************ Training Model : SAE engr0 + DNN ************\n",
            "\n",
            "Training DNN Classifier \n",
            "\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.0026 - loss: 7.2875\n",
            "Training SAE Complete .... \n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training on Stacked SAE - Train Device : OP3  Floorplan : engr0 \n",
            "\n",
            "\n",
            " Training Stacked SAE... \n",
            "\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\n",
            "*** Model Summary : STACKED_SAE_OP3_engr0 ***\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_248\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_248\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer_35 (\u001b[38;5;33mInputLayer\u001b[0m)           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m165\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_118 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115\u001b[0m)                           \u001b[38;5;34m19,090\u001b[0m \n",
              "\n",
              " dense_119 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                             \u001b[38;5;34m9,280\u001b[0m \n",
              "\n",
              " dense_120 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)                             \u001b[38;5;34m4,536\u001b[0m \n",
              "\n",
              " dense_121 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)                             \u001b[38;5;34m2,223\u001b[0m \n",
              "\n",
              " dense_122 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)                             \u001b[38;5;34m2,240\u001b[0m \n",
              "\n",
              " dense_123 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                             \u001b[38;5;34m4,560\u001b[0m \n",
              "\n",
              " dense_124 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115\u001b[0m)                            \u001b[38;5;34m9,315\u001b[0m \n",
              "\n",
              " dense_125 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m165\u001b[0m)                           \u001b[38;5;34m19,140\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " input_layer_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_118 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">19,090</span> \n",
              "\n",
              " dense_119 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">9,280</span> \n",
              "\n",
              " dense_120 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">4,536</span> \n",
              "\n",
              " dense_121 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,223</span> \n",
              "\n",
              " dense_122 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,240</span> \n",
              "\n",
              " dense_123 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">4,560</span> \n",
              "\n",
              " dense_124 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">9,315</span> \n",
              "\n",
              " dense_125 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">19,140</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m211,154\u001b[0m (824.82 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">211,154</span> (824.82 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m70,384\u001b[0m (274.94 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,384</span> (274.94 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m140,770\u001b[0m (549.89 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">140,770</span> (549.89 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "************ Training Model : STACKED_SAE engr0 + DNN ************\n",
            "\n",
            "Training DNN Classifier \n",
            "\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 188ms/step - accuracy: 0.0081 - loss: 7.8847\n",
            "Training STACKED SAE Complete .... \n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training on GAN - Train Device : OP3  Floorplan : engr0 \n",
            "\n",
            "\n",
            " Training GAN... \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
            "  warnings.warn(\"The model does not have any trainable weights.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*** Model Summary : GAN_OP3_engr0 ***\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_22\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_22\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " dense_128 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m165\u001b[0m)                           \u001b[38;5;34m27,390\u001b[0m \n",
              "\n",
              " dense_129 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m165\u001b[0m)                           \u001b[38;5;34m27,390\u001b[0m \n",
              "\n",
              " dense_130 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m165\u001b[0m)                           \u001b[38;5;34m27,390\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " dense_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">27,390</span> \n",
              "\n",
              " dense_129 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">27,390</span> \n",
              "\n",
              " dense_130 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">27,390</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m82,170\u001b[0m (320.98 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,170</span> (320.98 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m82,170\u001b[0m (320.98 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,170</span> (320.98 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "************ Training Model : GAN engr0 + DNN ************\n",
            "\n",
            "Training DNN Classifier \n",
            "\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.0168 - loss: 7.2470\n",
            "Training GAN Complete .... \n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training on FGSM with Epsilon = 1.0 - Train Device : OP3  Floorplan : engr0 \n",
            "\n",
            "\n",
            "************ Training Model : FGSM 1.0 engr0 + DNN ************\n",
            "\n",
            "Training DNN Classifier \n",
            "\n",
            "Epoch 1/2\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - accuracy: 0.0142 - loss: 12.3516\n",
            "Epoch 2/2\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0149 - loss: 4.4868    \n",
            "Training FGSM Complete .... \n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training on PGD with Epsilon = 1.0 - Train Device : OP3  Floorplan : engr0 \n",
            "\n",
            "\n",
            "************ Training Model : PGD 1.0 engr0 + DNN ************\n",
            "\n",
            "Training DNN Classifier \n",
            "\n",
            "Epoch 1/2\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.0149 - loss: 11.1941\n",
            "Epoch 2/2\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0150 - loss: 4.2658\n",
            "Training PGD Complete .... \n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training on MIM with Epsilon = 1.0 - Train Device : OP3  Floorplan : engr0 \n",
            "\n",
            "\n",
            "************ Training Model : MIM 1.0 engr0 + DNN ************\n",
            "\n",
            "Training DNN Classifier \n",
            "\n",
            "Epoch 1/2\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.0212 - loss: 10.4683\n",
            "Epoch 2/2\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0295 - loss: 4.1574 \n",
            "Training MIM Complete .... \n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Train dev -> OP3   flp -> engr1 \n",
            "\n",
            "Training on Original RSS - Train Device : OP3  Floorplan : engr1 \n",
            "\n",
            "\n",
            "************ Training Model : ORIGINAL engr1 + DNN ************\n",
            "\n",
            "Training DNN Classifier \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 195ms/step - accuracy: 0.0157 - loss: 3.8899\n",
            "\n",
            "*** Model Summary : ORIGINAL_DNN_OP3_eps_0_engr1 ***\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_28\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_28\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " dense_142 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                           \u001b[38;5;34m21,248\u001b[0m \n",
              "\n",
              " gaussian_noise_34 (\u001b[38;5;33mGaussianNoise\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_34 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_143 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                             \u001b[38;5;34m6,192\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " dense_142 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">21,248</span> \n",
              "\n",
              " gaussian_noise_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_143 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">6,192</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m82,322\u001b[0m (321.57 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,322</span> (321.57 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m27,440\u001b[0m (107.19 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,440</span> (107.19 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m54,882\u001b[0m (214.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,882</span> (214.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ORIGINAL Complete .... \n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training on SAE  - Train Device : OP3  Floorplan : engr1 \n",
            "\n",
            "\n",
            " Training Standard Autoencoder... \n",
            "\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\n",
            "*** Model Summary : SAE_OP3_engr1 ***\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_292\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_292\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer_48 (\u001b[38;5;33mInputLayer\u001b[0m)           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m165\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_144 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115\u001b[0m)                           \u001b[38;5;34m19,090\u001b[0m \n",
              "\n",
              " dense_145 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                             \u001b[38;5;34m9,280\u001b[0m \n",
              "\n",
              " dense_146 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)                             \u001b[38;5;34m4,536\u001b[0m \n",
              "\n",
              " dense_147 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)                             \u001b[38;5;34m2,223\u001b[0m \n",
              "\n",
              " dense_148 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)                             \u001b[38;5;34m2,240\u001b[0m \n",
              "\n",
              " dense_149 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                             \u001b[38;5;34m4,560\u001b[0m \n",
              "\n",
              " dense_150 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115\u001b[0m)                            \u001b[38;5;34m9,315\u001b[0m \n",
              "\n",
              " dense_151 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m165\u001b[0m)                           \u001b[38;5;34m19,140\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " input_layer_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_144 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">19,090</span> \n",
              "\n",
              " dense_145 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">9,280</span> \n",
              "\n",
              " dense_146 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">4,536</span> \n",
              "\n",
              " dense_147 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,223</span> \n",
              "\n",
              " dense_148 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,240</span> \n",
              "\n",
              " dense_149 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">4,560</span> \n",
              "\n",
              " dense_150 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">9,315</span> \n",
              "\n",
              " dense_151 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">19,140</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m211,154\u001b[0m (824.82 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">211,154</span> (824.82 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m70,384\u001b[0m (274.94 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,384</span> (274.94 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m140,770\u001b[0m (549.89 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">140,770</span> (549.89 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "************ Training Model : SAE engr1 + DNN ************\n",
            "\n",
            "Training DNN Classifier \n",
            "\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0194 - loss: 3.8529    \n",
            "Training SAE Complete .... \n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training on Stacked SAE - Train Device : OP3  Floorplan : engr1 \n",
            "\n",
            "\n",
            " Training Stacked SAE... \n",
            "\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\n",
            "*** Model Summary : STACKED_SAE_OP3_engr1 ***\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_305\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_305\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer_50 (\u001b[38;5;33mInputLayer\u001b[0m)           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m165\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_162 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115\u001b[0m)                           \u001b[38;5;34m19,090\u001b[0m \n",
              "\n",
              " dense_163 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                             \u001b[38;5;34m9,280\u001b[0m \n",
              "\n",
              " dense_164 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)                             \u001b[38;5;34m4,536\u001b[0m \n",
              "\n",
              " dense_165 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)                             \u001b[38;5;34m2,223\u001b[0m \n",
              "\n",
              " dense_166 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)                             \u001b[38;5;34m2,240\u001b[0m \n",
              "\n",
              " dense_167 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                             \u001b[38;5;34m4,560\u001b[0m \n",
              "\n",
              " dense_168 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115\u001b[0m)                            \u001b[38;5;34m9,315\u001b[0m \n",
              "\n",
              " dense_169 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m165\u001b[0m)                           \u001b[38;5;34m19,140\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " input_layer_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_162 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">19,090</span> \n",
              "\n",
              " dense_163 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">9,280</span> \n",
              "\n",
              " dense_164 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">4,536</span> \n",
              "\n",
              " dense_165 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,223</span> \n",
              "\n",
              " dense_166 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">2,240</span> \n",
              "\n",
              " dense_167 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">4,560</span> \n",
              "\n",
              " dense_168 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">9,315</span> \n",
              "\n",
              " dense_169 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">19,140</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m211,154\u001b[0m (824.82 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">211,154</span> (824.82 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m70,384\u001b[0m (274.94 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,384</span> (274.94 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m140,770\u001b[0m (549.89 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">140,770</span> (549.89 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "************ Training Model : STACKED_SAE engr1 + DNN ************\n",
            "\n",
            "Training DNN Classifier \n",
            "\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0169 - loss: 3.8797    \n",
            "Training STACKED SAE Complete .... \n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training on GAN - Train Device : OP3  Floorplan : engr1 \n",
            "\n",
            "\n",
            " Training GAN... \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
            "  warnings.warn(\"The model does not have any trainable weights.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*** Model Summary : GAN_OP3_engr1 ***\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_31\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_31\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " dense_172 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m165\u001b[0m)                           \u001b[38;5;34m27,390\u001b[0m \n",
              "\n",
              " dense_173 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m165\u001b[0m)                           \u001b[38;5;34m27,390\u001b[0m \n",
              "\n",
              " dense_174 (\u001b[38;5;33mDense\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m165\u001b[0m)                           \u001b[38;5;34m27,390\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " dense_172 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">27,390</span> \n",
              "\n",
              " dense_173 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">27,390</span> \n",
              "\n",
              " dense_174 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">27,390</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m82,170\u001b[0m (320.98 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,170</span> (320.98 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m82,170\u001b[0m (320.98 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,170</span> (320.98 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "************ Training Model : GAN engr1 + DNN ************\n",
            "\n",
            "Training DNN Classifier \n",
            "\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0205 - loss: 4.0505\n",
            "Training GAN Complete .... \n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training on FGSM with Epsilon = 1.0 - Train Device : OP3  Floorplan : engr1 \n",
            "\n",
            "\n",
            "************ Training Model : FGSM 1.0 engr1 + DNN ************\n",
            "\n",
            "Training DNN Classifier \n",
            "\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0577 - loss: 4.0459\n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1354 - loss: 3.2770 \n",
            "Training FGSM Complete .... \n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training on PGD with Epsilon = 1.0 - Train Device : OP3  Floorplan : engr1 \n",
            "\n",
            "\n",
            "************ Training Model : PGD 1.0 engr1 + DNN ************\n",
            "\n",
            "Training DNN Classifier \n",
            "\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0390 - loss: 3.8399    \n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1553 - loss: 3.0780 \n",
            "Training PGD Complete .... \n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "Training on MIM with Epsilon = 1.0 - Train Device : OP3  Floorplan : engr1 \n",
            "\n",
            "\n",
            "************ Training Model : MIM 1.0 engr1 + DNN ************\n",
            "\n",
            "Training DNN Classifier \n",
            "\n",
            "Epoch 1/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0607 - loss: 3.7852    \n",
            "Epoch 2/2\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1317 - loss: 3.1538 \n",
            "Training MIM Complete .... \n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# KNN, GPC, SVM, RF, CatBoost, XgBoost, LightGBM, MLP, DNN, CNN, Attention, Transformer, VIT\n",
        "\n",
        "# [JJ] [IB] : Make sure to update this variable while running other models\n",
        "# Define the ML model to train\n",
        "model_name = 'DNN'\n",
        "\n",
        "# Training Device\n",
        "train = 'OP3'\n",
        "\n",
        "# Testing Device\n",
        "dev = ['BLU','HTC','LG','MOTO','OP3','S7', 'i12p', 'nk7', 'pxl4']\n",
        "\n",
        "# Building Floorplans\n",
        "# ['engr0', 'engr1', 'glover', 'sciences', 'libstudy']\n",
        "floorplan = ['engr0', 'engr1', 'glover', 'sciences', 'libstudy']\n",
        "\n",
        "# Different augmentations to train the ML model\n",
        "augmented_data = ['ORIGINAL', 'SAE', 'STACKED_SAE', 'GAN', 'FGSM', 'PGD', 'MIM']\n",
        "\n",
        "mode = ['ORIGINAL', 'SAE', 'STACKED_SAE', 'GAN']\n",
        "\n",
        "# Test the trained model on different conditions\n",
        "attack = ['ORIGINAL', 'FGSM', 'PGD', 'MIM']\n",
        "\n",
        "# Perturbation strength for Adversarial Methods (FGSM, PGD, MIM)\n",
        "# [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "epsilon = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "\n",
        "train_ap_dict = {}\n",
        "\n",
        "for flp in floorplan:\n",
        "    print(f'\\n Train dev -> {train}   flp -> {flp} \\n')\n",
        "    # Initial CI only !!!\n",
        "    ci_val = 0\n",
        "    train_x, train_y, train_aps = train_data(ci_val,train, flp)\n",
        "    train_ap_dict[f'{train}_{flp}'] = train_aps\n",
        "    sorted_indices = np.argsort(train_y)\n",
        "    train_x = train_x[sorted_indices]\n",
        "    train_y = train_y[sorted_indices]\n",
        "\n",
        "    for aug in augmented_data:\n",
        "      if aug == 'ORIGINAL':\n",
        "        print(f'Training on Original RSS - Train Device : {train}  Floorplan : {flp} \\n')\n",
        "\n",
        "        print(f'\\n************ Training Model : {aug} {flp} + {model_name} ************\\n')\n",
        "\n",
        "        # [JJ] [IB] : Add more if conditions for other models\n",
        "        if model_name == 'DNN':\n",
        "          model = train_DNN(train_x, train_y, 1, batch_size=128)\n",
        "          save_name = f'{aug}_{model_name}_eps_0_train_{train}_{flp}'\n",
        "          model.save(f'{save_name}.keras')\n",
        "          model_params(model, f'{aug}_{model_name}_{train}_eps_0_{flp}')\n",
        "\n",
        "        print(f'Training ORIGINAL Complete .... \\n')\n",
        "        print('--------------------------------------------------------------------------------------------')\n",
        "        print('--------------------------------------------------------------------------------------------')\n",
        "\n",
        "      if aug == 'SAE':\n",
        "        print(f'Training on SAE  - Train Device : {train}  Floorplan : {flp} \\n')\n",
        "        # Replace this with other models to train\n",
        "        sae_x, sae_y, sae_model = sae(int(train_x.shape[-1]), train_x, train_y, 9)\n",
        "        model_params(sae_model, f'{aug}_{train}_{flp}')\n",
        "        sae_org_x = np.concatenate((train_x, sae_x), axis=0)\n",
        "        sae_org_y = np.concatenate((train_y, sae_y), axis=0)\n",
        "        print(f'\\n************ Training Model : {aug} {flp} + {model_name} ************\\n')\n",
        "\n",
        "        # [JJ] [IB] : Add more if conditions for other models\n",
        "        if model_name == 'DNN':\n",
        "          model = train_DNN(sae_org_x, sae_org_y, 1, batch_size=128)\n",
        "          save_name = f'{aug}_{model_name}_eps_0_train_{train}_{flp}'\n",
        "          model.save(f'{save_name}.keras')\n",
        "          # model_params(model, f'{aug}_{model_name}_{train}_eps_0_{flp}')\n",
        "\n",
        "        print(f'Training SAE Complete .... \\n')\n",
        "        print('--------------------------------------------------------------------------------------------')\n",
        "        print('--------------------------------------------------------------------------------------------')\n",
        "\n",
        "      if aug == 'STACKED_SAE':\n",
        "        print(f'Training on Stacked SAE - Train Device : {train}  Floorplan : {flp} \\n')\n",
        "        # Replace this with other models to train\n",
        "        stacked_sae_x, stacked_sae_y, stacked_sae_model = stacked_sae(int(train_x.shape[-1]), train_x, train_y, 9)\n",
        "        model_params(stacked_sae_model, f'{aug}_{train}_{flp}')\n",
        "        sta_sae_org_x = np.concatenate((train_x, stacked_sae_x), axis=0)\n",
        "        sta_sae_org_y = np.concatenate((train_y, stacked_sae_y), axis=0)\n",
        "        print(f'\\n************ Training Model : {aug} {flp} + {model_name} ************\\n')\n",
        "\n",
        "        # [JJ] [IB] : Add more if conditions for other models\n",
        "        if model_name == 'DNN':\n",
        "          model = train_DNN(sta_sae_org_x, sta_sae_org_y, 1, batch_size=128)\n",
        "          save_name = f'{aug}_{model_name}_eps_0_train_{train}_{flp}'\n",
        "          model.save(f'{save_name}.keras')\n",
        "          # model_params(model, f'{aug}_{model_name}_{train}_eps_0_{flp}')\n",
        "\n",
        "        print(f'Training STACKED SAE Complete .... \\n')\n",
        "        print('--------------------------------------------------------------------------------------------')\n",
        "        print('--------------------------------------------------------------------------------------------')\n",
        "\n",
        "      if aug == 'GAN':\n",
        "        print(f'Training on GAN - Train Device : {train}  Floorplan : {flp} \\n')\n",
        "        # Replace this with other models to train\n",
        "        gan_x, gan_y, gan_model = train_gan(train_x, train_y, noise_dim=int(train_x.shape[-1]), batch_size=int(train_x.shape[0]), epochs=20)\n",
        "        model_params(gan_model, f'{aug}_{train}_{flp}')\n",
        "        gan_org_x = np.concatenate((train_x, gan_x), axis=0)\n",
        "        gan_org_y = np.concatenate((train_y, gan_y), axis=0)\n",
        "        print(f'\\n************ Training Model : {aug} {flp} + {model_name} ************\\n')\n",
        "\n",
        "        # [JJ] [IB] : Add more if conditions for other models\n",
        "        if model_name == 'DNN':\n",
        "          model = train_DNN(gan_org_x, gan_org_y, 1, batch_size=128)\n",
        "          save_name = f'{aug}_{model_name}_eps_0_train_{train}_{flp}'\n",
        "          model.save(f'{save_name}.keras')\n",
        "          # model_params(model, f'{aug}_{model_name}_{train}_eps_0_{flp}')\n",
        "\n",
        "        print(f'Training GAN Complete .... \\n')\n",
        "        print('--------------------------------------------------------------------------------------------')\n",
        "        print('--------------------------------------------------------------------------------------------')\n",
        "\n",
        "      if aug == 'FGSM':\n",
        "        for eps in epsilon:\n",
        "          print(f'Training on FGSM with Epsilon = {eps} - Train Device : {train}  Floorplan : {flp} \\n')\n",
        "          model = tf.keras.models.load_model(f'ORIGINAL_{model_name}_eps_0_train_{train}_{flp}.keras')\n",
        "          if model:\n",
        "            fgsm_x, fgsm_y = train_fgsm(train_x, train_y, eps, model)\n",
        "            fgsm_org_x = np.concatenate((train_x, fgsm_x), axis=0)\n",
        "            fgsm_org_y = np.concatenate((train_y, fgsm_y), axis=0)\n",
        "            print(f'\\n************ Training Model : {aug} {eps} {flp} + {model_name} ************\\n')\n",
        "\n",
        "            # [JJ] [IB] : Add more if conditions for other models\n",
        "            if model_name == 'DNN':\n",
        "              model = train_DNN(fgsm_org_x, fgsm_org_y, 2, batch_size=128)\n",
        "              save_name = f'{aug}_{model_name}_eps_{eps}_train_{train}_{flp}'\n",
        "              model.save(f'{save_name}.keras')\n",
        "              # model_params(model, f'{aug}_{model_name}_{train}_eps_{eps}_{flp}')\n",
        "          else:\n",
        "            print(f'Pre-trained model required for {aug}')\n",
        "        print(f'Training FGSM Complete .... \\n')\n",
        "        print('--------------------------------------------------------------------------------------------')\n",
        "        print('--------------------------------------------------------------------------------------------')\n",
        "\n",
        "      if aug == 'PGD':\n",
        "        for eps in epsilon:\n",
        "          print(f'Training on PGD with Epsilon = {eps} - Train Device : {train}  Floorplan : {flp} \\n')\n",
        "          model = tf.keras.models.load_model(f'ORIGINAL_{model_name}_eps_0_train_{train}_{flp}.keras')\n",
        "          if model:\n",
        "            pgd_x, pgd_y = train_pgd(train_x, train_y, eps, model)\n",
        "            pgd_org_x = np.concatenate((train_x, pgd_x), axis=0)\n",
        "            pgd_org_y = np.concatenate((train_y, pgd_y), axis=0)\n",
        "            print(f'\\n************ Training Model : {aug} {eps} {flp} + {model_name} ************\\n')\n",
        "\n",
        "            # [JJ] [IB] : Add more if conditions for other models\n",
        "            if model_name == 'DNN':\n",
        "              model = train_DNN(pgd_org_x, pgd_org_y, 2, batch_size=128)\n",
        "              save_name = f'{aug}_{model_name}_eps_{eps}_train_{train}_{flp}'\n",
        "              model.save(f'{save_name}.keras')\n",
        "              # model_params(model, f'{aug}_{model_name}_{train}_eps_{eps}_{flp}')\n",
        "          else:\n",
        "            print(f'Pre-trained model required for {aug}')\n",
        "        print(f'Training PGD Complete .... \\n')\n",
        "        print('--------------------------------------------------------------------------------------------')\n",
        "        print('--------------------------------------------------------------------------------------------')\n",
        "\n",
        "      if aug == 'MIM':\n",
        "        for eps in epsilon:\n",
        "          print(f'Training on MIM with Epsilon = {eps} - Train Device : {train}  Floorplan : {flp} \\n')\n",
        "          model = tf.keras.models.load_model(f'ORIGINAL_{model_name}_eps_0_train_{train}_{flp}.keras')\n",
        "          if model:\n",
        "            mim_x, mim_y = train_mim(train_x, train_y, eps, model)\n",
        "            mim_org_x = np.concatenate((train_x, mim_x), axis=0)\n",
        "            mim_org_y = np.concatenate((train_y, mim_y), axis=0)\n",
        "            print(f'\\n************ Training Model : {aug} {eps} {flp} + {model_name} ************\\n')\n",
        "\n",
        "            # [JJ] [IB] : Add more if conditions for other models\n",
        "            if model_name == 'DNN':\n",
        "              model = train_DNN(mim_org_x, mim_org_y, 2, batch_size=128)\n",
        "              save_name = f'{aug}_{model_name}_eps_{eps}_train_{train}_{flp}'\n",
        "              model.save(f'{save_name}.keras')\n",
        "              # model_params(model, f'{aug}_{model_name}_{train}_eps_{eps}_{flp}')\n",
        "          else:\n",
        "            print(f'Pre-trained model required for {aug}')\n",
        "        print(f'Training MIM Complete .... \\n')\n",
        "        print('--------------------------------------------------------------------------------------------')\n",
        "        print('--------------------------------------------------------------------------------------------')\n",
        "\n",
        "zip_filename = f'{model_name}_models.zip'\n",
        "# Create a Zip\n",
        "with ZipFile(zip_filename, 'w') as zipf:\n",
        "    for foldername, subfolders, filenames in os.walk('.'):\n",
        "        for filename in filenames:\n",
        "            if filename.endswith('.keras') or filename.endswith('.txt'):\n",
        "                filepath = os.path.join(foldername, filename)\n",
        "                zipf.write(filepath, os.path.relpath(filepath, start='.'))\n",
        "\n",
        "# files.download(zip_filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrMCDZpd8Eo6",
        "outputId": "524a1144-5943-47f3-f3eb-3a5f32620976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------------------\n",
            "Testing on Original RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr0 Model -> ORIGINAL DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
            "Mean Error : 15.508196721311476 Median Error : 15.0\n",
            "\n",
            " Test dev -> HTC  flp -> engr0 Model -> ORIGINAL DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 15.508196721311476 Median Error : 15.0\n",
            "\n",
            " Test dev -> LG  flp -> engr0 Model -> ORIGINAL DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 15.508196721311476 Median Error : 15.0\n",
            "\n",
            " Test dev -> MOTO  flp -> engr0 Model -> ORIGINAL DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 15.508196721311476 Median Error : 15.0\n",
            "\n",
            " Test dev -> OP3  flp -> engr0 Model -> ORIGINAL DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 15.508196721311476 Median Error : 15.0\n",
            "\n",
            " Test dev -> S7  flp -> engr0 Model -> ORIGINAL DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 15.508196721311476 Median Error : 15.0\n",
            "\n",
            " Test dev -> i12p  flp -> engr0 Model -> ORIGINAL DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Mean Error : 11.121951219512194 Median Error : 10.0\n",
            "\n",
            " Test dev -> nk7  flp -> engr0 Model -> ORIGINAL DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Mean Error : 11.19047619047619 Median Error : 10.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr0 Model -> ORIGINAL DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 11.19047619047619 Median Error : 10.5\n",
            "[WARNING] : ORIGINAL_DNN_eps_1.0_train_OP3_engr0.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on Original RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr1 Model -> ORIGINAL DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
            "Mean Error : 23.5 Median Error : 23.5\n",
            "\n",
            " Test dev -> HTC  flp -> engr1 Model -> ORIGINAL DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 23.5 Median Error : 23.5\n",
            "\n",
            " Test dev -> LG  flp -> engr1 Model -> ORIGINAL DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 23.5 Median Error : 23.5\n",
            "\n",
            " Test dev -> MOTO  flp -> engr1 Model -> ORIGINAL DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 23.5 Median Error : 23.5\n",
            "\n",
            " Test dev -> OP3  flp -> engr1 Model -> ORIGINAL DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 23.5 Median Error : 23.5\n",
            "\n",
            " Test dev -> S7  flp -> engr1 Model -> ORIGINAL DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 23.5 Median Error : 23.5\n",
            "\n",
            " Test dev -> i12p  flp -> engr1 Model -> ORIGINAL DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Mean Error : 20.5 Median Error : 20.5\n",
            "\n",
            " Test dev -> nk7  flp -> engr1 Model -> ORIGINAL DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 20.476190476190474 Median Error : 20.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr1 Model -> ORIGINAL DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Mean Error : 20.976744186046513 Median Error : 21.0\n",
            "[WARNING] : ORIGINAL_DNN_eps_1.0_train_OP3_engr1.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on Original RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr0 Model -> SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "Mean Error : 25.491803278688526 Median Error : 25.0\n",
            "\n",
            " Test dev -> HTC  flp -> engr0 Model -> SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 25.491803278688526 Median Error : 25.0\n",
            "\n",
            " Test dev -> LG  flp -> engr0 Model -> SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 25.491803278688526 Median Error : 25.0\n",
            "\n",
            " Test dev -> MOTO  flp -> engr0 Model -> SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 25.491803278688526 Median Error : 25.0\n",
            "\n",
            " Test dev -> OP3  flp -> engr0 Model -> SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Mean Error : 25.491803278688526 Median Error : 25.0\n",
            "\n",
            " Test dev -> S7  flp -> engr0 Model -> SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 25.491803278688526 Median Error : 25.0\n",
            "\n",
            " Test dev -> i12p  flp -> engr0 Model -> SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Mean Error : 15.731707317073171 Median Error : 15.0\n",
            "\n",
            " Test dev -> nk7  flp -> engr0 Model -> SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Mean Error : 16.19047619047619 Median Error : 15.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr0 Model -> SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Mean Error : 16.19047619047619 Median Error : 15.5\n",
            "[WARNING] : SAE_DNN_eps_1.0_train_OP3_engr0.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on Original RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr1 Model -> SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
            "Mean Error : 23.5 Median Error : 23.5\n",
            "\n",
            " Test dev -> HTC  flp -> engr1 Model -> SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 23.5 Median Error : 23.5\n",
            "\n",
            " Test dev -> LG  flp -> engr1 Model -> SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "Mean Error : 23.5 Median Error : 23.5\n",
            "\n",
            " Test dev -> MOTO  flp -> engr1 Model -> SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "Mean Error : 23.5 Median Error : 23.5\n",
            "\n",
            " Test dev -> OP3  flp -> engr1 Model -> SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 23.5 Median Error : 23.5\n",
            "\n",
            " Test dev -> S7  flp -> engr1 Model -> SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 23.5 Median Error : 23.5\n",
            "\n",
            " Test dev -> i12p  flp -> engr1 Model -> SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Mean Error : 20.5 Median Error : 20.5\n",
            "\n",
            " Test dev -> nk7  flp -> engr1 Model -> SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 20.476190476190474 Median Error : 20.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr1 Model -> SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "Mean Error : 20.976744186046513 Median Error : 21.0\n",
            "[WARNING] : SAE_DNN_eps_1.0_train_OP3_engr1.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on Original RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr0 Model -> STACKED_SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
            "Mean Error : 20.557377049180328 Median Error : 18.0\n",
            "\n",
            " Test dev -> HTC  flp -> engr0 Model -> STACKED_SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 20.557377049180328 Median Error : 18.0\n",
            "\n",
            " Test dev -> LG  flp -> engr0 Model -> STACKED_SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "Mean Error : 20.557377049180328 Median Error : 18.0\n",
            "\n",
            " Test dev -> MOTO  flp -> engr0 Model -> STACKED_SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 20.557377049180328 Median Error : 18.0\n",
            "\n",
            " Test dev -> OP3  flp -> engr0 Model -> STACKED_SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Mean Error : 20.557377049180328 Median Error : 18.0\n",
            "\n",
            " Test dev -> S7  flp -> engr0 Model -> STACKED_SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 20.557377049180328 Median Error : 18.0\n",
            "\n",
            " Test dev -> i12p  flp -> engr0 Model -> STACKED_SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Mean Error : 28.0 Median Error : 28.0\n",
            "\n",
            " Test dev -> nk7  flp -> engr0 Model -> STACKED_SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Mean Error : 27.523809523809526 Median Error : 27.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr0 Model -> STACKED_SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Mean Error : 27.523809523809526 Median Error : 27.5\n",
            "[WARNING] : STACKED_SAE_DNN_eps_1.0_train_OP3_engr0.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on Original RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr1 Model -> STACKED_SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "Mean Error : 21.625 Median Error : 21.5\n",
            "\n",
            " Test dev -> HTC  flp -> engr1 Model -> STACKED_SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 21.625 Median Error : 21.5\n",
            "\n",
            " Test dev -> LG  flp -> engr1 Model -> STACKED_SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 21.625 Median Error : 21.5\n",
            "\n",
            " Test dev -> MOTO  flp -> engr1 Model -> STACKED_SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 21.625 Median Error : 21.5\n",
            "\n",
            " Test dev -> OP3  flp -> engr1 Model -> STACKED_SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Mean Error : 21.625 Median Error : 21.5\n",
            "\n",
            " Test dev -> S7  flp -> engr1 Model -> STACKED_SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 21.625 Median Error : 21.5\n",
            "\n",
            " Test dev -> i12p  flp -> engr1 Model -> STACKED_SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Mean Error : 18.642857142857142 Median Error : 18.5\n",
            "\n",
            " Test dev -> nk7  flp -> engr1 Model -> STACKED_SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 18.61904761904762 Median Error : 18.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr1 Model -> STACKED_SAE DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Mean Error : 19.11627906976744 Median Error : 19.0\n",
            "[WARNING] : STACKED_SAE_DNN_eps_1.0_train_OP3_engr1.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on Original RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr0 Model -> GAN DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
            "Mean Error : 29.0327868852459 Median Error : 29.0\n",
            "\n",
            " Test dev -> HTC  flp -> engr0 Model -> GAN DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 29.0327868852459 Median Error : 29.0\n",
            "\n",
            " Test dev -> LG  flp -> engr0 Model -> GAN DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 29.0327868852459 Median Error : 29.0\n",
            "\n",
            " Test dev -> MOTO  flp -> engr0 Model -> GAN DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 18.016393442622952 Median Error : 15.0\n",
            "\n",
            " Test dev -> OP3  flp -> engr0 Model -> GAN DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 29.0327868852459 Median Error : 29.0\n",
            "\n",
            " Test dev -> S7  flp -> engr0 Model -> GAN DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 29.0327868852459 Median Error : 29.0\n",
            "\n",
            " Test dev -> i12p  flp -> engr0 Model -> GAN DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Mean Error : 19.048780487804876 Median Error : 19.0\n",
            "\n",
            " Test dev -> nk7  flp -> engr0 Model -> GAN DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Mean Error : 19.523809523809526 Median Error : 19.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr0 Model -> GAN DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 10.761904761904763 Median Error : 10.5\n",
            "[WARNING] : GAN_DNN_eps_1.0_train_OP3_engr0.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on Original RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr1 Model -> GAN DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "Mean Error : 16.375 Median Error : 14.5\n",
            "\n",
            " Test dev -> HTC  flp -> engr1 Model -> GAN DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Mean Error : 16.375 Median Error : 14.5\n",
            "\n",
            " Test dev -> LG  flp -> engr1 Model -> GAN DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 16.375 Median Error : 14.5\n",
            "\n",
            " Test dev -> MOTO  flp -> engr1 Model -> GAN DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 16.375 Median Error : 14.5\n",
            "\n",
            " Test dev -> OP3  flp -> engr1 Model -> GAN DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 16.375 Median Error : 14.5\n",
            "\n",
            " Test dev -> S7  flp -> engr1 Model -> GAN DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 16.375 Median Error : 14.5\n",
            "\n",
            " Test dev -> i12p  flp -> engr1 Model -> GAN DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Mean Error : 17.785714285714285 Median Error : 17.5\n",
            "\n",
            " Test dev -> nk7  flp -> engr1 Model -> GAN DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 17.761904761904763 Median Error : 17.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr1 Model -> GAN DNN Attack -> ORIGINAL Epsilon -> N/A \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Mean Error : 17.441860465116278 Median Error : 17.0\n",
            "[WARNING] : GAN_DNN_eps_1.0_train_OP3_engr1.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on Original RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on Original RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on Original RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on Original RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on Original RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on Original RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "Inference Complete .... \n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on FGSM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : ORIGINAL_DNN_eps_1.0_train_OP3_engr0.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on FGSM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : ORIGINAL_DNN_eps_1.0_train_OP3_engr1.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on FGSM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : SAE_DNN_eps_1.0_train_OP3_engr0.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on FGSM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : SAE_DNN_eps_1.0_train_OP3_engr1.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on FGSM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : STACKED_SAE_DNN_eps_1.0_train_OP3_engr0.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on FGSM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : STACKED_SAE_DNN_eps_1.0_train_OP3_engr1.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on FGSM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : GAN_DNN_eps_1.0_train_OP3_engr0.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on FGSM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : GAN_DNN_eps_1.0_train_OP3_engr1.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on FGSM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "Mean Error : 30.0 Median Error : 30.0\n",
            "\n",
            " Test dev -> HTC  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Mean Error : 30.0 Median Error : 30.0\n",
            "\n",
            " Test dev -> LG  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 30.0 Median Error : 30.0\n",
            "\n",
            " Test dev -> MOTO  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 30.0 Median Error : 30.0\n",
            "\n",
            " Test dev -> OP3  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 30.0 Median Error : 30.0\n",
            "\n",
            " Test dev -> S7  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 30.0 Median Error : 30.0\n",
            "\n",
            " Test dev -> i12p  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Mean Error : 20.0 Median Error : 20.0\n",
            "\n",
            " Test dev -> nk7  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Mean Error : 20.476190476190474 Median Error : 20.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 20.476190476190474 Median Error : 20.5\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on FGSM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
            "Mean Error : 15.25 Median Error : 12.5\n",
            "\n",
            " Test dev -> HTC  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 19.916666666666668 Median Error : 19.5\n",
            "\n",
            " Test dev -> LG  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 19.916666666666668 Median Error : 19.5\n",
            "\n",
            " Test dev -> MOTO  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 19.916666666666668 Median Error : 19.5\n",
            "\n",
            " Test dev -> OP3  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 19.916666666666668 Median Error : 19.5\n",
            "\n",
            " Test dev -> S7  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 19.916666666666668 Median Error : 19.5\n",
            "\n",
            " Test dev -> i12p  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Mean Error : 16.976190476190474 Median Error : 16.5\n",
            "\n",
            " Test dev -> nk7  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 16.952380952380953 Median Error : 16.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Mean Error : 17.441860465116278 Median Error : 17.0\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on FGSM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
            "Mean Error : 25.491803278688526 Median Error : 25.0\n",
            "\n",
            " Test dev -> HTC  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
            "Mean Error : 25.491803278688526 Median Error : 25.0\n",
            "\n",
            " Test dev -> LG  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 25.491803278688526 Median Error : 25.0\n",
            "\n",
            " Test dev -> MOTO  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 26.327868852459016 Median Error : 26.0\n",
            "\n",
            " Test dev -> OP3  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "Mean Error : 25.950819672131146 Median Error : 25.0\n",
            "\n",
            " Test dev -> S7  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Mean Error : 25.491803278688526 Median Error : 25.0\n",
            "\n",
            " Test dev -> i12p  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "Mean Error : 15.731707317073171 Median Error : 15.0\n",
            "\n",
            " Test dev -> nk7  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
            "Mean Error : 16.19047619047619 Median Error : 15.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Mean Error : 16.80952380952381 Median Error : 15.5\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on FGSM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "Mean Error : 17.666666666666668 Median Error : 16.5\n",
            "\n",
            " Test dev -> HTC  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 17.666666666666668 Median Error : 16.5\n",
            "\n",
            " Test dev -> LG  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 17.666666666666668 Median Error : 16.5\n",
            "\n",
            " Test dev -> MOTO  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Mean Error : 17.666666666666668 Median Error : 16.5\n",
            "\n",
            " Test dev -> OP3  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 17.666666666666668 Median Error : 16.5\n",
            "\n",
            " Test dev -> S7  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 17.666666666666668 Median Error : 16.5\n",
            "\n",
            " Test dev -> i12p  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Mean Error : 19.547619047619047 Median Error : 19.5\n",
            "\n",
            " Test dev -> nk7  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 19.523809523809526 Median Error : 19.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Mean Error : 19.11627906976744 Median Error : 19.0\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on FGSM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "Mean Error : 29.0327868852459 Median Error : 29.0\n",
            "\n",
            " Test dev -> HTC  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 29.0327868852459 Median Error : 29.0\n",
            "\n",
            " Test dev -> LG  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Mean Error : 29.0327868852459 Median Error : 29.0\n",
            "\n",
            " Test dev -> MOTO  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 29.0327868852459 Median Error : 29.0\n",
            "\n",
            " Test dev -> OP3  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 29.0327868852459 Median Error : 29.0\n",
            "\n",
            " Test dev -> S7  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 29.0327868852459 Median Error : 29.0\n",
            "\n",
            " Test dev -> i12p  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Mean Error : 19.048780487804876 Median Error : 19.0\n",
            "\n",
            " Test dev -> nk7  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Mean Error : 19.523809523809526 Median Error : 19.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 19.523809523809526 Median Error : 19.5\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on FGSM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
            "Mean Error : 21.625 Median Error : 21.5\n",
            "\n",
            " Test dev -> HTC  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "Mean Error : 22.541666666666668 Median Error : 22.5\n",
            "\n",
            " Test dev -> LG  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 22.541666666666668 Median Error : 22.5\n",
            "\n",
            " Test dev -> MOTO  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 22.541666666666668 Median Error : 22.5\n",
            "\n",
            " Test dev -> OP3  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 22.541666666666668 Median Error : 22.5\n",
            "\n",
            " Test dev -> S7  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 22.541666666666668 Median Error : 22.5\n",
            "\n",
            " Test dev -> i12p  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Mean Error : 19.547619047619047 Median Error : 19.5\n",
            "\n",
            " Test dev -> nk7  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 19.523809523809526 Median Error : 19.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> FGSM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Mean Error : 20.023255813953487 Median Error : 20.0\n",
            "--------------------------------------------------------------------------------------------\n",
            "Inference Complete .... \n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on PGD RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : ORIGINAL_DNN_eps_1.0_train_OP3_engr0.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on PGD RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : ORIGINAL_DNN_eps_1.0_train_OP3_engr1.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on PGD RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : SAE_DNN_eps_1.0_train_OP3_engr0.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on PGD RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : SAE_DNN_eps_1.0_train_OP3_engr1.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on PGD RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : STACKED_SAE_DNN_eps_1.0_train_OP3_engr0.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on PGD RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : STACKED_SAE_DNN_eps_1.0_train_OP3_engr1.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on PGD RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : GAN_DNN_eps_1.0_train_OP3_engr0.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on PGD RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : GAN_DNN_eps_1.0_train_OP3_engr1.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on PGD RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "Mean Error : 30.0 Median Error : 30.0\n",
            "\n",
            " Test dev -> HTC  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 30.0 Median Error : 30.0\n",
            "\n",
            " Test dev -> LG  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 30.0 Median Error : 30.0\n",
            "\n",
            " Test dev -> MOTO  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Mean Error : 30.0 Median Error : 30.0\n",
            "\n",
            " Test dev -> OP3  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 30.0 Median Error : 30.0\n",
            "\n",
            " Test dev -> S7  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 30.0 Median Error : 30.0\n",
            "\n",
            " Test dev -> i12p  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Mean Error : 20.0 Median Error : 20.0\n",
            "\n",
            " Test dev -> nk7  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Mean Error : 20.476190476190474 Median Error : 20.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 20.476190476190474 Median Error : 20.5\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on PGD RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "Mean Error : 15.25 Median Error : 12.5\n",
            "\n",
            " Test dev -> HTC  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Mean Error : 19.916666666666668 Median Error : 19.5\n",
            "\n",
            " Test dev -> LG  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
            "Mean Error : 19.916666666666668 Median Error : 19.5\n",
            "\n",
            " Test dev -> MOTO  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 19.916666666666668 Median Error : 19.5\n",
            "\n",
            " Test dev -> OP3  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 19.916666666666668 Median Error : 19.5\n",
            "\n",
            " Test dev -> S7  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 19.916666666666668 Median Error : 19.5\n",
            "\n",
            " Test dev -> i12p  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "Mean Error : 16.976190476190474 Median Error : 16.5\n",
            "\n",
            " Test dev -> nk7  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Mean Error : 16.952380952380953 Median Error : 16.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "Mean Error : 17.441860465116278 Median Error : 17.0\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on PGD RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "Mean Error : 15.262295081967213 Median Error : 15.0\n",
            "\n",
            " Test dev -> HTC  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 15.262295081967213 Median Error : 15.0\n",
            "\n",
            " Test dev -> LG  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 15.262295081967213 Median Error : 15.0\n",
            "\n",
            " Test dev -> MOTO  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 15.262295081967213 Median Error : 15.0\n",
            "\n",
            " Test dev -> OP3  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Mean Error : 15.262295081967213 Median Error : 15.0\n",
            "\n",
            " Test dev -> S7  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 15.262295081967213 Median Error : 15.0\n",
            "\n",
            " Test dev -> i12p  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Mean Error : 13.195121951219512 Median Error : 11.0\n",
            "\n",
            " Test dev -> nk7  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Mean Error : 13.095238095238095 Median Error : 10.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 13.095238095238095 Median Error : 10.5\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on PGD RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
            "Mean Error : 17.666666666666668 Median Error : 16.5\n",
            "\n",
            " Test dev -> HTC  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 17.666666666666668 Median Error : 16.5\n",
            "\n",
            " Test dev -> LG  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 17.666666666666668 Median Error : 16.5\n",
            "\n",
            " Test dev -> MOTO  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 17.666666666666668 Median Error : 16.5\n",
            "\n",
            " Test dev -> OP3  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 17.666666666666668 Median Error : 16.5\n",
            "\n",
            " Test dev -> S7  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Mean Error : 17.666666666666668 Median Error : 16.5\n",
            "\n",
            " Test dev -> i12p  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Mean Error : 19.547619047619047 Median Error : 19.5\n",
            "\n",
            " Test dev -> nk7  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 19.523809523809526 Median Error : 19.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Mean Error : 19.11627906976744 Median Error : 19.0\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on PGD RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "Mean Error : 24.688524590163933 Median Error : 24.0\n",
            "\n",
            " Test dev -> HTC  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 24.688524590163933 Median Error : 24.0\n",
            "\n",
            " Test dev -> LG  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 24.688524590163933 Median Error : 24.0\n",
            "\n",
            " Test dev -> MOTO  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 18.016393442622952 Median Error : 15.0\n",
            "\n",
            " Test dev -> OP3  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 18.016393442622952 Median Error : 15.0\n",
            "\n",
            " Test dev -> S7  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Mean Error : 24.688524590163933 Median Error : 24.0\n",
            "\n",
            " Test dev -> i12p  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Mean Error : 15.024390243902438 Median Error : 14.0\n",
            "\n",
            " Test dev -> nk7  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Mean Error : 15.476190476190476 Median Error : 14.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 10.761904761904763 Median Error : 10.5\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on PGD RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
            "Mean Error : 22.541666666666668 Median Error : 22.5\n",
            "\n",
            " Test dev -> HTC  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 22.375 Median Error : 22.5\n",
            "\n",
            " Test dev -> LG  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 22.166666666666668 Median Error : 22.5\n",
            "\n",
            " Test dev -> MOTO  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 22.229166666666668 Median Error : 22.5\n",
            "\n",
            " Test dev -> OP3  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 22.4375 Median Error : 22.5\n",
            "\n",
            " Test dev -> S7  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 22.416666666666668 Median Error : 22.5\n",
            "\n",
            " Test dev -> i12p  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Mean Error : 19.547619047619047 Median Error : 19.5\n",
            "\n",
            " Test dev -> nk7  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 19.523809523809526 Median Error : 19.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> PGD Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "Mean Error : 20.023255813953487 Median Error : 20.0\n",
            "--------------------------------------------------------------------------------------------\n",
            "Inference Complete .... \n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on MIM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : ORIGINAL_DNN_eps_1.0_train_OP3_engr0.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on MIM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : ORIGINAL_DNN_eps_1.0_train_OP3_engr1.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on MIM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : SAE_DNN_eps_1.0_train_OP3_engr0.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on MIM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : SAE_DNN_eps_1.0_train_OP3_engr1.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on MIM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : STACKED_SAE_DNN_eps_1.0_train_OP3_engr0.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on MIM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : STACKED_SAE_DNN_eps_1.0_train_OP3_engr1.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on MIM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : GAN_DNN_eps_1.0_train_OP3_engr0.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on MIM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "[WARNING] : GAN_DNN_eps_1.0_train_OP3_engr1.keras Model not found!\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on MIM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
            "Mean Error : 30.0 Median Error : 30.0\n",
            "\n",
            " Test dev -> HTC  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 30.0 Median Error : 30.0\n",
            "\n",
            " Test dev -> LG  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 30.0 Median Error : 30.0\n",
            "\n",
            " Test dev -> MOTO  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 30.0 Median Error : 30.0\n",
            "\n",
            " Test dev -> OP3  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 30.0 Median Error : 30.0\n",
            "\n",
            " Test dev -> S7  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 30.0 Median Error : 30.0\n",
            "\n",
            " Test dev -> i12p  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Mean Error : 20.0 Median Error : 20.0\n",
            "\n",
            " Test dev -> nk7  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Mean Error : 20.476190476190474 Median Error : 20.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr0 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 20.476190476190474 Median Error : 20.5\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on MIM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
            "Mean Error : 15.25 Median Error : 12.5\n",
            "\n",
            " Test dev -> HTC  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 19.916666666666668 Median Error : 19.5\n",
            "\n",
            " Test dev -> LG  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Mean Error : 19.916666666666668 Median Error : 19.5\n",
            "\n",
            " Test dev -> MOTO  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 19.916666666666668 Median Error : 19.5\n",
            "\n",
            " Test dev -> OP3  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 19.916666666666668 Median Error : 19.5\n",
            "\n",
            " Test dev -> S7  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 19.916666666666668 Median Error : 19.5\n",
            "\n",
            " Test dev -> i12p  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Mean Error : 16.976190476190474 Median Error : 16.5\n",
            "\n",
            " Test dev -> nk7  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 16.952380952380953 Median Error : 16.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr1 Model -> FGSM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Mean Error : 17.441860465116278 Median Error : 17.0\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on MIM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
            "Mean Error : 15.262295081967213 Median Error : 15.0\n",
            "\n",
            " Test dev -> HTC  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 15.262295081967213 Median Error : 15.0\n",
            "\n",
            " Test dev -> LG  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 15.262295081967213 Median Error : 15.0\n",
            "\n",
            " Test dev -> MOTO  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 15.262295081967213 Median Error : 15.0\n",
            "\n",
            " Test dev -> OP3  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 15.262295081967213 Median Error : 15.0\n",
            "\n",
            " Test dev -> S7  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 15.262295081967213 Median Error : 15.0\n",
            "\n",
            " Test dev -> i12p  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Mean Error : 13.195121951219512 Median Error : 11.0\n",
            "\n",
            " Test dev -> nk7  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Mean Error : 13.095238095238095 Median Error : 10.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr0 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 13.095238095238095 Median Error : 10.5\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on MIM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
            "Mean Error : 17.666666666666668 Median Error : 16.5\n",
            "\n",
            " Test dev -> HTC  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Mean Error : 17.666666666666668 Median Error : 16.5\n",
            "\n",
            " Test dev -> LG  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Mean Error : 17.666666666666668 Median Error : 16.5\n",
            "\n",
            " Test dev -> MOTO  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 17.666666666666668 Median Error : 16.5\n",
            "\n",
            " Test dev -> OP3  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 17.666666666666668 Median Error : 16.5\n",
            "\n",
            " Test dev -> S7  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "Mean Error : 17.666666666666668 Median Error : 16.5\n",
            "\n",
            " Test dev -> i12p  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Mean Error : 19.547619047619047 Median Error : 19.5\n",
            "\n",
            " Test dev -> nk7  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Mean Error : 19.523809523809526 Median Error : 19.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr1 Model -> PGD DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Mean Error : 19.11627906976744 Median Error : 19.0\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on MIM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
            "Mean Error : 24.688524590163933 Median Error : 24.0\n",
            "\n",
            " Test dev -> HTC  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 24.688524590163933 Median Error : 24.0\n",
            "\n",
            " Test dev -> LG  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 24.688524590163933 Median Error : 24.0\n",
            "\n",
            " Test dev -> MOTO  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 18.016393442622952 Median Error : 15.0\n",
            "\n",
            " Test dev -> OP3  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
            "Mean Error : 18.016393442622952 Median Error : 15.0\n",
            "\n",
            " Test dev -> S7  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "Mean Error : 24.688524590163933 Median Error : 24.0\n",
            "\n",
            " Test dev -> i12p  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "Mean Error : 15.024390243902438 Median Error : 14.0\n",
            "\n",
            " Test dev -> nk7  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Mean Error : 15.476190476190476 Median Error : 14.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr0 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 10.761904761904763 Median Error : 10.5\n",
            "--------------------------------------------------------------------------------------------\n",
            "Testing on MIM RSS\n",
            "\n",
            "--------------------------------------------------------------------------------------------\n",
            "\n",
            " Test dev -> BLU  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
            "Mean Error : 22.541666666666668 Median Error : 22.5\n",
            "\n",
            " Test dev -> HTC  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Mean Error : 22.375 Median Error : 22.5\n",
            "\n",
            " Test dev -> LG  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Mean Error : 22.166666666666668 Median Error : 22.5\n",
            "\n",
            " Test dev -> MOTO  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 22.229166666666668 Median Error : 22.5\n",
            "\n",
            " Test dev -> OP3  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Mean Error : 22.4375 Median Error : 22.5\n",
            "\n",
            " Test dev -> S7  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 22.416666666666668 Median Error : 22.5\n",
            "\n",
            " Test dev -> i12p  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Mean Error : 19.547619047619047 Median Error : 19.5\n",
            "\n",
            " Test dev -> nk7  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Mean Error : 19.523809523809526 Median Error : 19.5\n",
            "\n",
            " Test dev -> pxl4  flp -> engr1 Model -> MIM DNN Train Epsilon -> 1.0 Attack -> MIM Test Epsilon -> 1.0 \n",
            "\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Mean Error : 20.023255813953487 Median Error : 20.0\n",
            "--------------------------------------------------------------------------------------------\n",
            "Inference Complete .... \n",
            "\n",
            "--------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Testing the Trained MOdels\n",
        "summary_data = []\n",
        "\n",
        "for att in attack:\n",
        "  if att == 'ORIGINAL':\n",
        "    for aug in augmented_data:\n",
        "      for flp in floorplan:\n",
        "        print('--------------------------------------------------------------------------------------------')\n",
        "        print(f'Testing on Original RSS\\n')\n",
        "        print('--------------------------------------------------------------------------------------------')\n",
        "        if aug in mode:\n",
        "          train_eps = 0\n",
        "          try:\n",
        "            model = tf.keras.models.load_model(f'{aug}_{model_name}_eps_{train_eps}_train_{train}_{flp}.keras')\n",
        "          except:\n",
        "            print(f'[WARNING] : {aug}_{model_name}_eps_{train_eps}_train_{train}_{flp}.keras Model not found!')\n",
        "\n",
        "          for device in dev:\n",
        "            print(f'\\n Test dev -> {device}  flp -> {flp} Model -> {aug} {model_name} Attack -> {att} Epsilon -> N/A \\n')\n",
        "            # Initial CI only !!!\n",
        "            ci_val = 0\n",
        "            train_aps_value = train_ap_dict[f'{train}_{flp}']\n",
        "            test_x, test_y = test_data(ci_val, train_aps_value, device, flp)\n",
        "            predictions = model.predict(test_x)\n",
        "            prediction_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "            mean_error = np.abs(prediction_classes - test_y)\n",
        "            df = pd.DataFrame({'Prediction': prediction_classes, 'Actual': test_y, 'Error': mean_error})\n",
        "\n",
        "\n",
        "            summary_data.append({\n",
        "                'Floorplan': flp,\n",
        "                'Device': device,\n",
        "                'Training Data': aug,\n",
        "                'Training Epsilon': train_eps,\n",
        "                'Attack': att,\n",
        "                'Inference Epsilon': test_eps,\n",
        "                'Mean Error': np.mean(mean_error),\n",
        "                'Median Error': np.median(mean_error),\n",
        "                'Min Error': np.min(mean_error),\n",
        "                'Max Error': np.max(mean_error)\n",
        "            })\n",
        "            print(f'Mean Error : {np.mean(mean_error)} Median Error : {np.median(mean_error)}')\n",
        "\n",
        "            df.to_csv(f'{aug}_{model_name}_train_{train}_{flp}_test_{device}.csv', index=False)\n",
        "\n",
        "          else:\n",
        "            for train_eps in epsilon:\n",
        "              try:\n",
        "                model = tf.keras.models.load_model(f'{aug}_{model_name}_eps_{train_eps}_train_{train}_{flp}.keras')\n",
        "                flag = 1\n",
        "              except:\n",
        "                print(f'[WARNING] : {aug}_{model_name}_eps_{train_eps}_train_{train}_{flp}.keras Model not found!')\n",
        "                flag = -1\n",
        "\n",
        "              if flag == 1:\n",
        "                for device in dev:\n",
        "                  print(f'\\n Test dev -> {device}  flp -> {flp} Model -> {aug} {model_name} Train Epsilon -> {train_eps} Attack -> {att}\\n')\n",
        "                  # Initial CI only !!!\n",
        "                  ci_val = 0\n",
        "                  train_aps_value = train_ap_dict[f'{train}_{flp}']\n",
        "                  test_x, test_y = test_data(ci_val, train_aps_value, device, flp)\n",
        "                  fgsm_x, fgsm_y = train_fgsm(test_x, test_y, 0, model)\n",
        "                  predictions = model.predict(fgsm_x)\n",
        "                  prediction_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "                  mean_error = np.abs(prediction_classes - test_y)\n",
        "                  df = pd.DataFrame({'Prediction': prediction_classes, 'Actual': test_y, 'Error': mean_error})\n",
        "\n",
        "\n",
        "                  summary_data.append({\n",
        "                      'Floorplan': flp,\n",
        "                      'Device': device,\n",
        "                      'Training Data': aug,\n",
        "                      'Training Epsilon': train_eps,\n",
        "                      'Attack': att,\n",
        "                      'Inference Epsilon': test_eps,\n",
        "                      'Mean Error': np.mean(mean_error),\n",
        "                      'Median Error': np.median(mean_error),\n",
        "                      'Min Error': np.min(mean_error),\n",
        "                      'Max Error': np.max(mean_error)\n",
        "                  })\n",
        "                  print(f'Mean Error : {np.mean(mean_error)} Median Error : {np.median(mean_error)}')\n",
        "\n",
        "                  df.to_csv(f'{aug}_{model_name}_train_{train}_trainEPS_{train_eps}_{flp}_test_{device}.csv', index=False)\n",
        "      # summary.to_csv(f'Summary_{aug}_{model_name}_train_{train}_{flp}_test_{device}.csv', index=False)\n",
        "    print('--------------------------------------------------------------------------------------------')\n",
        "    print(f'Inference Complete .... \\n')\n",
        "    print('--------------------------------------------------------------------------------------------')\n",
        "\n",
        "  if att == 'FGSM':\n",
        "    for aug in augmented_data:\n",
        "      for flp in floorplan:\n",
        "        print('--------------------------------------------------------------------------------------------')\n",
        "        print(f'Testing on FGSM RSS\\n')\n",
        "        print('--------------------------------------------------------------------------------------------')\n",
        "        for train_eps in epsilon:\n",
        "          try:\n",
        "            model = tf.keras.models.load_model(f'{aug}_{model_name}_eps_{train_eps}_train_{train}_{flp}.keras')\n",
        "            flag = 1\n",
        "          except:\n",
        "            print(f'[WARNING] : {aug}_{model_name}_eps_{train_eps}_train_{train}_{flp}.keras Model not found!')\n",
        "            flag = -1\n",
        "\n",
        "          if flag == 1:\n",
        "            for device in dev:\n",
        "              for test_eps in epsilon:\n",
        "                print(f'\\n Test dev -> {device}  flp -> {flp} Model -> {aug} {model_name} Train Epsilon -> {train_eps} Attack -> {att} Test Epsilon -> {test_eps} \\n')\n",
        "                # Initial CI only !!!\n",
        "                ci_val = 0\n",
        "                train_aps_value = train_ap_dict[f'{train}_{flp}']\n",
        "                test_x, test_y = test_data(ci_val, train_aps_value, device, flp)\n",
        "                fgsm_x, fgsm_y = train_fgsm(test_x, test_y, test_eps, model)\n",
        "                predictions = model.predict(fgsm_x)\n",
        "                prediction_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "                mean_error = np.abs(prediction_classes - test_y)\n",
        "                df = pd.DataFrame({'Prediction': prediction_classes, 'Actual': test_y, 'Error': mean_error})\n",
        "\n",
        "                summary_data.append({\n",
        "                    'Floorplan': flp,\n",
        "                    'Device': device,\n",
        "                    'Training Data': aug,\n",
        "                    'Training Epsilon': train_eps,\n",
        "                    'Attack': att,\n",
        "                    'Inference Epsilon': test_eps,\n",
        "                    'Mean Error': np.mean(mean_error),\n",
        "                    'Median Error': np.median(mean_error),\n",
        "                    'Min Error': np.min(mean_error),\n",
        "                    'Max Error': np.max(mean_error)\n",
        "                })\n",
        "                print(f'Mean Error : {np.mean(mean_error)} Median Error : {np.median(mean_error)}')\n",
        "\n",
        "                df.to_csv(f'{aug}_{model_name}_train_{train}_trainEPS_{train_eps}_{flp}_test_{device}_testEPS_{test_eps}.csv', index=False)\n",
        "      # summary.to_csv(f'Summary_{aug}_{model_name}_train_{train}_{flp}_test_{device}.csv', index=False)\n",
        "    print('--------------------------------------------------------------------------------------------')\n",
        "    print(f'Inference Complete .... \\n')\n",
        "    print('--------------------------------------------------------------------------------------------')\n",
        "\n",
        "  if att == 'PGD':\n",
        "    for aug in augmented_data:\n",
        "      for flp in floorplan:\n",
        "        print('--------------------------------------------------------------------------------------------')\n",
        "        print(f'Testing on PGD RSS\\n')\n",
        "        print('--------------------------------------------------------------------------------------------')\n",
        "        for train_eps in epsilon:\n",
        "          try:\n",
        "            model = tf.keras.models.load_model(f'{aug}_{model_name}_eps_{train_eps}_train_{train}_{flp}.keras')\n",
        "            flag = 1\n",
        "          except:\n",
        "            print(f'[WARNING] : {aug}_{model_name}_eps_{train_eps}_train_{train}_{flp}.keras Model not found!')\n",
        "            flag = -1\n",
        "\n",
        "          if flag == 1:\n",
        "            for device in dev:\n",
        "              for test_eps in epsilon:\n",
        "                print(f'\\n Test dev -> {device}  flp -> {flp} Model -> {aug} {model_name} Train Epsilon -> {train_eps} Attack -> {att} Test Epsilon -> {test_eps} \\n')\n",
        "                ci_val = 0\n",
        "                train_aps_value = train_ap_dict[f'{train}_{flp}']\n",
        "                test_x, test_y = test_data(ci_val, train_aps_value, device, flp)\n",
        "                pgd_x, pgd_y = train_pgd(test_x, test_y, test_eps, model)\n",
        "                predictions = model.predict(pgd_x)\n",
        "                prediction_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "                mean_error = np.abs(prediction_classes - test_y)\n",
        "                df = pd.DataFrame({'Prediction': prediction_classes, 'Actual': test_y, 'Error': mean_error})\n",
        "\n",
        "                summary_data.append({\n",
        "                    'Floorplan': flp,\n",
        "                    'Device': device,\n",
        "                    'Training Data': aug,\n",
        "                    'Training Epsilon': train_eps,\n",
        "                    'Attack': att,\n",
        "                    'Inference Epsilon': test_eps,\n",
        "                    'Mean Error': np.mean(mean_error),\n",
        "                    'Median Error': np.median(mean_error),\n",
        "                    'Min Error': np.min(mean_error),\n",
        "                    'Max Error': np.max(mean_error)\n",
        "                })\n",
        "                print(f'Mean Error : {np.mean(mean_error)} Median Error : {np.median(mean_error)}')\n",
        "\n",
        "                df.to_csv(f'{aug}_{model_name}_train_{train}_trainEPS_{train_eps}_{flp}_test_{device}_testEPS_{test_eps}.csv', index=False)\n",
        "      # summary.to_csv(f'Summary_{aug}_{model_name}_train_{train}_{flp}_test_{device}.csv', index=False)\n",
        "    print('--------------------------------------------------------------------------------------------')\n",
        "    print(f'Inference Complete .... \\n')\n",
        "    print('--------------------------------------------------------------------------------------------')\n",
        "\n",
        "  if att == 'MIM':\n",
        "      for aug in augmented_data:\n",
        "        for flp in floorplan:\n",
        "          print('--------------------------------------------------------------------------------------------')\n",
        "          print(f'Testing on MIM RSS\\n')\n",
        "          print('--------------------------------------------------------------------------------------------')\n",
        "          for train_eps in epsilon:\n",
        "            try:\n",
        "              model = tf.keras.models.load_model(f'{aug}_{model_name}_eps_{train_eps}_train_{train}_{flp}.keras')\n",
        "              flag = 1\n",
        "            except:\n",
        "              print(f'[WARNING] : {aug}_{model_name}_eps_{train_eps}_train_{train}_{flp}.keras Model not found!')\n",
        "              flag = -1\n",
        "\n",
        "            if flag == 1:\n",
        "              for device in dev:\n",
        "                for test_eps in epsilon:\n",
        "                  print(f'\\n Test dev -> {device}  flp -> {flp} Model -> {aug} {model_name} Train Epsilon -> {train_eps} Attack -> {att} Test Epsilon -> {test_eps} \\n')\n",
        "                  # Initial CI only !!!\n",
        "                  ci_val = 0\n",
        "                  train_aps_value = train_ap_dict[f'{train}_{flp}']\n",
        "                  test_x, test_y = test_data(ci_val, train_aps_value, device, flp)\n",
        "                  mim_x, mim_y = train_pgd(test_x, test_y, test_eps, model)\n",
        "                  predictions = model.predict(mim_x)\n",
        "                  prediction_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "                  mean_error = np.abs(prediction_classes - test_y)\n",
        "                  df = pd.DataFrame({'Prediction': prediction_classes, 'Actual': test_y, 'Error': mean_error})\n",
        "\n",
        "                  summary_data.append({\n",
        "                      'Floorplan': flp,\n",
        "                      'Device': device,\n",
        "                      'Training Data': aug,\n",
        "                      'Training Epsilon': train_eps,\n",
        "                      'Attack': att,\n",
        "                      'Inference Epsilon': test_eps,\n",
        "                      'Mean Error': np.mean(mean_error),\n",
        "                      'Median Error': np.median(mean_error),\n",
        "                      'Min Error': np.min(mean_error),\n",
        "                      'Max Error': np.max(mean_error)\n",
        "                  })\n",
        "                  print(f'Mean Error : {np.mean(mean_error)} Median Error : {np.median(mean_error)}')\n",
        "\n",
        "                  df.to_csv(f'{aug}_{model_name}_train_{train}_trainEPS_{train_eps}_{flp}_test_{device}_testEPS_{test_eps}.csv', index=False)\n",
        "        # summary.to_csv(f'Summary_{aug}_{model_name}_train_{train}_{flp}_test_{device}.csv', index=False)\n",
        "      print('--------------------------------------------------------------------------------------------')\n",
        "      print(f'Inference Complete .... \\n')\n",
        "      print('--------------------------------------------------------------------------------------------')\n",
        "\n",
        "summary = pd.DataFrame(summary_data)\n",
        "summary.to_csv(f'Summary_{model_name}.csv', index=False)\n",
        "zip_filename = f'{model_name}_complete.zip'\n",
        "# Create a Zip\n",
        "with ZipFile(zip_filename, 'w') as zipf:\n",
        "    for foldername, subfolders, filenames in os.walk('.'):\n",
        "        for filename in filenames:\n",
        "            if filename.endswith('.keras') or filename.endswith('.txt') or filename.endswith('.csv'):\n",
        "                filepath = os.path.join(foldername, filename)\n",
        "                zipf.write(filepath, os.path.relpath(filepath, start='.'))\n",
        "\n",
        "# files.download(zip_filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dHeQ1c2J3q3"
      },
      "outputs": [],
      "source": [
        "''' Author - Danish Gufran\n",
        "           - Jadon Johnson\n",
        "           - Isaac Blair\n",
        "           - Sudeep Pasricha\n",
        "\n",
        "EPIC Lab : Colorado State University, Fort Collins\n",
        "\n",
        "<Danish.Gufran@colostate.edu>\n",
        "<Jadon.Johnson@colostate.edu>\n",
        "<Isaac.Blair@colostate.edu>\n",
        "<Sudeep@colostate.edu>\n",
        "\n",
        "Title - Data Augmentation Methods for Wi-Fi RSS Fingerprinting Based Indoor Localization.\n",
        "\n",
        "Citation :\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjrIn6_-6NXI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}